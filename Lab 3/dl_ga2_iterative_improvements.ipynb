{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dl_ga2_iterative_improvements.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAN7aedvjj4z",
        "colab_type": "code",
        "outputId": "8d7f24ed-4bfa-4d8a-c0a8-2704f1a30ea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#imports and Drive mounting\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn as sk\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 2020\n",
        "np.random.seed(seed)  \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGIwUnVInurG",
        "colab_type": "code",
        "outputId": "ed7d1ec7-21e5-4faa-f15c-a785089c3e2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bHIXiGlnuxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_history(history):\n",
        "  plt.figure(figsize = (12,4))\n",
        "  plt.subplot(1,2,1)\n",
        "\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.plot(history.epoch, np.array(history.history['accuracy']),'g-',\n",
        "           label='Train accuracy')\n",
        "  plt.plot(history.epoch, np.array(history.history['val_accuracy']),'r-',\n",
        "           label = 'Validation accuracy')\n",
        "  plt.ylim([0.0,1.0])\n",
        "  plt.legend()\n",
        "\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss minimised by model')\n",
        "  plt.plot(history.epoch, np.array(history.history['loss']),'g-',\n",
        "           label='Train loss')\n",
        "  plt.plot(history.epoch, np.array(history.history['val_loss']),'r-',\n",
        "           label = 'Validation loss')\n",
        "  plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P-2_C8xnu0D",
        "colab_type": "code",
        "outputId": "65c70369-5227-4295-882e-aa7f30932434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# Load the data: CIFAR100 with 20 class labels\n",
        "(x_train_all, r_train_all_class), ( _ , _ ) = cifar100.load_data(label_mode='coarse')\n",
        "\n",
        "num_classes = 20\n",
        "\n",
        "val_size = 6000\n",
        "# make validation set\n",
        "x_train, x_val, r_train_class, r_val_class = train_test_split(x_train_all, r_train_all_class, test_size=val_size, random_state=0)\n",
        "\n",
        "# let's again take a subset of the training data first, for playing around\n",
        "# Note that such a subset is only useful if it can guide your tuning process,\n",
        "# i.e., if it leads you to similar decisions as you would make on the whole training set\n",
        "\n",
        "# In this case, 10000 samples is really too small: you can check this by comparing the validation curves \n",
        "# for 10000 training samples with those for all training samples. \n",
        "# The validation accuracy should not be very different!\n",
        "\n",
        "x_train_small = x_train[:20000]\n",
        "r_train_small_class = r_train_class[:20000]\n",
        "\n",
        "# And we do the same standardization as in the first assignment\n",
        "x_train_all = x_train_all.astype('float32')\n",
        "x_train = x_train.astype('float32')\n",
        "x_train_small = x_train_small.astype('float32')\n",
        "x_val = x_val.astype('float32')\n",
        "\n",
        "x_train_all /= 255.0\n",
        "x_train /= 255.0\n",
        "x_train_small /= 255.0\n",
        "x_val /= 255.0\n",
        "\n",
        "# the labels from the downloaded data are integer numbers\n",
        "# for a multi-class classification task, we again convert each integer\n",
        "# to a vector with 19 zeros and a single '1', corresponding to the right class\n",
        "r_train_all = tf.keras.utils.to_categorical(r_train_all_class, num_classes)\n",
        "r_train = tf.keras.utils.to_categorical(r_train_class, num_classes)\n",
        "r_train_small = tf.keras.utils.to_categorical(r_train_small_class, num_classes)\n",
        "r_val = tf.keras.utils.to_categorical(r_val_class, num_classes)\n",
        "\n",
        "\n",
        "# Labels\n",
        "labels = [\n",
        "'aquatic mammals',\n",
        "'fish',\n",
        "'flowers',\n",
        "'food containers',\n",
        "'fruit and vegetables',\n",
        "'household electrical devices',\n",
        "'household furniture',\n",
        "'insects',\n",
        "'large carnivores',\n",
        "'large man-made outdoor things',\n",
        "'large natural outdoor scenes',\n",
        "'large omnivores and herbivores',\n",
        "'medium-sized mammals',\n",
        "'non-insect invertebrates',\n",
        "'people',\n",
        "'reptiles',\n",
        "'small mammals',\n",
        "'trees',\n",
        "'vehicles 1',\n",
        "'vehicles 2'\n",
        "]\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_val.shape[0], 'validation samples')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 6s 0us/step\n",
            "x_train shape: (44000, 32, 32, 3)\n",
            "44000 train samples\n",
            "6000 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuP2_izonu6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First, make the model more complex to lower bias\n",
        "\n",
        "def complex_model(nb_conv=0,nb_dense=0):\n",
        "  model = Sequential()\n",
        "\n",
        "  # Convolutional layers\n",
        "  model.add(Conv2D(64, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
        "  model.add(BatchNormalization(\n",
        "    axis=-1, momentum=0.95, epsilon=0.001, center=True, scale=True,\n",
        "    beta_initializer='zeros', gamma_initializer='ones',\n",
        "    moving_mean_initializer='zeros', moving_variance_initializer='ones',\n",
        "    beta_regularizer=None, gamma_regularizer=None, beta_constraint=None,\n",
        "    gamma_constraint=None, renorm=False, renorm_clipping=None, renorm_momentum=0.95,\n",
        "    fused=None, trainable=True, virtual_batch_size=None, adjustment=None, name=None,\n",
        "  ))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "  model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "  model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "  model.add(BatchNormalization(\n",
        "    axis=-1, momentum=0.95, epsilon=0.001, center=True, scale=True,\n",
        "    beta_initializer='zeros', gamma_initializer='ones',\n",
        "    moving_mean_initializer='zeros', moving_variance_initializer='ones',\n",
        "    beta_regularizer=None, gamma_regularizer=None, beta_constraint=None,\n",
        "    gamma_constraint=None, renorm=False, renorm_clipping=None, renorm_momentum=0.95,\n",
        "    fused=None, trainable=True, virtual_batch_size=None, adjustment=None, name=None,\n",
        "  ))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "  model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "  model.add(BatchNormalization(\n",
        "    axis=-1, momentum=0.95, epsilon=0.001, center=True, scale=True,\n",
        "    beta_initializer='zeros', gamma_initializer='ones',\n",
        "    moving_mean_initializer='zeros', moving_variance_initializer='ones',\n",
        "    beta_regularizer=None, gamma_regularizer=None, beta_constraint=None,\n",
        "    gamma_constraint=None, renorm=False, renorm_clipping=None, renorm_momentum=0.95,\n",
        "    fused=None, trainable=True, virtual_batch_size=None, adjustment=None, name=None,\n",
        "  ))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "  model.add(BatchNormalization(\n",
        "    axis=-1, momentum=0.95, epsilon=0.001, center=True, scale=True,\n",
        "    beta_initializer='zeros', gamma_initializer='ones',\n",
        "    moving_mean_initializer='zeros', moving_variance_initializer='ones',\n",
        "    beta_regularizer=None, gamma_regularizer=None, beta_constraint=None,\n",
        "    gamma_constraint=None, renorm=False, renorm_clipping=None, renorm_momentum=0.95,\n",
        "    fused=None, trainable=True, virtual_batch_size=None, adjustment=None, name=None,\n",
        "  ))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Activation('relu'))\n",
        "  \n",
        "  model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "  model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "  model.add(BatchNormalization(\n",
        "    axis=-1, momentum=0.95, epsilon=0.001, center=True, scale=True,\n",
        "    beta_initializer='zeros', gamma_initializer='ones',\n",
        "    moving_mean_initializer='zeros', moving_variance_initializer='ones',\n",
        "    beta_regularizer=None, gamma_regularizer=None, beta_constraint=None,\n",
        "    gamma_constraint=None, renorm=False, renorm_clipping=None, renorm_momentum=0.95,\n",
        "    fused=None, trainable=True, virtual_batch_size=None, adjustment=None, name=None,\n",
        "  ))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "  model.add(BatchNormalization(\n",
        "    axis=-1, momentum=0.95, epsilon=0.001, center=True, scale=True,\n",
        "    beta_initializer='zeros', gamma_initializer='ones',\n",
        "    moving_mean_initializer='zeros', moving_variance_initializer='ones',\n",
        "    beta_regularizer=None, gamma_regularizer=None, beta_constraint=None,\n",
        "    gamma_constraint=None, renorm=False, renorm_clipping=None, renorm_momentum=0.95,\n",
        "    fused=None, trainable=True, virtual_batch_size=None, adjustment=None, name=None,\n",
        "  ))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(Conv2D(128, (1,1), padding='same'))\n",
        "  model.add(BatchNormalization(\n",
        "    axis=-1, momentum=0.95, epsilon=0.001, center=True, scale=True,\n",
        "    beta_initializer='zeros', gamma_initializer='ones',\n",
        "    moving_mean_initializer='zeros', moving_variance_initializer='ones',\n",
        "    beta_regularizer=None, gamma_regularizer=None, beta_constraint=None,\n",
        "    gamma_constraint=None, renorm=False, renorm_clipping=None, renorm_momentum=0.95,\n",
        "    fused=None, trainable=True, virtual_batch_size=None, adjustment=None, name=None,\n",
        "  ))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(Conv2D(128, (1,1), padding='same'))\n",
        "  model.add(BatchNormalization(\n",
        "    axis=-1, momentum=0.95, epsilon=0.001, center=True, scale=True,\n",
        "    beta_initializer='zeros', gamma_initializer='ones',\n",
        "    moving_mean_initializer='zeros', moving_variance_initializer='ones',\n",
        "    beta_regularizer=None, gamma_regularizer=None, beta_constraint=None,\n",
        "    gamma_constraint=None, renorm=False, renorm_clipping=None, renorm_momentum=0.95,\n",
        "    fused=None, trainable=True, virtual_batch_size=None, adjustment=None, name=None,\n",
        "  ))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  \n",
        "  # end of convolutional layers, start of 'hidden' dense layers (can be more than 1 if necessary)\n",
        "  model.add(Flatten())\n",
        "  #model.add(Dense(512))\n",
        "  #model.add(Activation('relu'))\n",
        "\n",
        "  # Final dense layer = linear classifier\n",
        "  #model.add(Dropout(0.1))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  opt = tf.keras.optimizers.Adam() #using defaults for now\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ojCu-T_nvAQ",
        "colab_type": "code",
        "outputId": "0f27f9cf-a624-45c2-a8fb-a6055d7f82db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = complex_model()\n",
        "model.summary()\n",
        "\n",
        "batch_size = 1024\n",
        "epochs = 500\n",
        "es_callback = EarlyStopping(monitor='val_accuracy', patience=10, min_delta=0.0001)\n",
        "\n",
        "history = model.fit(x_train, r_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          callbacks = [es_callback],\n",
        "          validation_data=(x_val, r_val),\n",
        "          shuffle=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_13 (Conv2D)           (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 32, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 32, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 4, 4, 128)         16512     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 4, 4, 128)         16512     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 2, 2, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                2580      \n",
            "_________________________________________________________________\n",
            "activation_22 (Activation)   (None, 20)                0         \n",
            "=================================================================\n",
            "Total params: 1,443,348\n",
            "Trainable params: 1,441,428\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/500\n",
            "44000/44000 [==============================] - 23s 529us/sample - loss: 2.4885 - accuracy: 0.2398 - val_loss: 3.1760 - val_accuracy: 0.0733\n",
            "Epoch 2/500\n",
            "44000/44000 [==============================] - 22s 510us/sample - loss: 2.0389 - accuracy: 0.3675 - val_loss: 2.7295 - val_accuracy: 0.1893\n",
            "Epoch 3/500\n",
            "44000/44000 [==============================] - 23s 522us/sample - loss: 1.7692 - accuracy: 0.4457 - val_loss: 1.9541 - val_accuracy: 0.4002\n",
            "Epoch 4/500\n",
            "44000/44000 [==============================] - 23s 529us/sample - loss: 1.5297 - accuracy: 0.5155 - val_loss: 1.6859 - val_accuracy: 0.4652\n",
            "Epoch 5/500\n",
            "44000/44000 [==============================] - 23s 520us/sample - loss: 1.3460 - accuracy: 0.5698 - val_loss: 1.6842 - val_accuracy: 0.4913\n",
            "Epoch 6/500\n",
            "44000/44000 [==============================] - 23s 520us/sample - loss: 1.1833 - accuracy: 0.6218 - val_loss: 1.4531 - val_accuracy: 0.5462\n",
            "Epoch 7/500\n",
            "44000/44000 [==============================] - 23s 524us/sample - loss: 1.0618 - accuracy: 0.6585 - val_loss: 1.4764 - val_accuracy: 0.5410\n",
            "Epoch 8/500\n",
            "44000/44000 [==============================] - 23s 525us/sample - loss: 0.9298 - accuracy: 0.7002 - val_loss: 1.7240 - val_accuracy: 0.5185\n",
            "Epoch 9/500\n",
            "44000/44000 [==============================] - 23s 523us/sample - loss: 0.8340 - accuracy: 0.7319 - val_loss: 1.5754 - val_accuracy: 0.5430\n",
            "Epoch 10/500\n",
            "44000/44000 [==============================] - 23s 522us/sample - loss: 0.7226 - accuracy: 0.7683 - val_loss: 1.3797 - val_accuracy: 0.5888\n",
            "Epoch 11/500\n",
            "44000/44000 [==============================] - 23s 522us/sample - loss: 0.6329 - accuracy: 0.7937 - val_loss: 1.4929 - val_accuracy: 0.5775\n",
            "Epoch 12/500\n",
            "44000/44000 [==============================] - 23s 522us/sample - loss: 0.5165 - accuracy: 0.8350 - val_loss: 1.4644 - val_accuracy: 0.6085\n",
            "Epoch 13/500\n",
            "44000/44000 [==============================] - 23s 523us/sample - loss: 0.4248 - accuracy: 0.8646 - val_loss: 1.7195 - val_accuracy: 0.5692\n",
            "Epoch 14/500\n",
            "44000/44000 [==============================] - 23s 524us/sample - loss: 0.3445 - accuracy: 0.8924 - val_loss: 1.6306 - val_accuracy: 0.5810\n",
            "Epoch 15/500\n",
            "44000/44000 [==============================] - 23s 525us/sample - loss: 0.2793 - accuracy: 0.9138 - val_loss: 1.6344 - val_accuracy: 0.5892\n",
            "Epoch 16/500\n",
            "44000/44000 [==============================] - 23s 524us/sample - loss: 0.2092 - accuracy: 0.9385 - val_loss: 1.5970 - val_accuracy: 0.5997\n",
            "Epoch 17/500\n",
            "44000/44000 [==============================] - 23s 525us/sample - loss: 0.1771 - accuracy: 0.9475 - val_loss: 1.8356 - val_accuracy: 0.5840\n",
            "Epoch 18/500\n",
            "44000/44000 [==============================] - 23s 525us/sample - loss: 0.1375 - accuracy: 0.9607 - val_loss: 2.0869 - val_accuracy: 0.5660\n",
            "Epoch 19/500\n",
            "44000/44000 [==============================] - 23s 526us/sample - loss: 0.1066 - accuracy: 0.9712 - val_loss: 1.9761 - val_accuracy: 0.5918\n",
            "Epoch 20/500\n",
            "44000/44000 [==============================] - 23s 524us/sample - loss: 0.0831 - accuracy: 0.9781 - val_loss: 1.8732 - val_accuracy: 0.6185\n",
            "Epoch 21/500\n",
            "44000/44000 [==============================] - 23s 524us/sample - loss: 0.0569 - accuracy: 0.9871 - val_loss: 1.9007 - val_accuracy: 0.6188\n",
            "Epoch 22/500\n",
            "44000/44000 [==============================] - 23s 524us/sample - loss: 0.0388 - accuracy: 0.9930 - val_loss: 1.8112 - val_accuracy: 0.6302\n",
            "Epoch 23/500\n",
            "44000/44000 [==============================] - 23s 524us/sample - loss: 0.0205 - accuracy: 0.9977 - val_loss: 1.8065 - val_accuracy: 0.6437\n",
            "Epoch 24/500\n",
            "44000/44000 [==============================] - 23s 524us/sample - loss: 0.0107 - accuracy: 0.9993 - val_loss: 1.7445 - val_accuracy: 0.6518\n",
            "Epoch 25/500\n",
            "44000/44000 [==============================] - 23s 524us/sample - loss: 0.0064 - accuracy: 0.9997 - val_loss: 1.7658 - val_accuracy: 0.6570\n",
            "Epoch 26/500\n",
            "44000/44000 [==============================] - 23s 524us/sample - loss: 0.0049 - accuracy: 0.9997 - val_loss: 1.7530 - val_accuracy: 0.6638\n",
            "Epoch 27/500\n",
            "44000/44000 [==============================] - 23s 525us/sample - loss: 0.0036 - accuracy: 0.9998 - val_loss: 1.7818 - val_accuracy: 0.6652\n",
            "Epoch 28/500\n",
            "44000/44000 [==============================] - 23s 523us/sample - loss: 0.0030 - accuracy: 0.9998 - val_loss: 1.7801 - val_accuracy: 0.6645\n",
            "Epoch 29/500\n",
            "44000/44000 [==============================] - 23s 525us/sample - loss: 0.0033 - accuracy: 0.9997 - val_loss: 1.8485 - val_accuracy: 0.6595\n",
            "Epoch 30/500\n",
            "44000/44000 [==============================] - 23s 524us/sample - loss: 0.0025 - accuracy: 0.9999 - val_loss: 1.8123 - val_accuracy: 0.6667\n",
            "Epoch 31/500\n",
            "44000/44000 [==============================] - 23s 524us/sample - loss: 0.0028 - accuracy: 0.9998 - val_loss: 1.7953 - val_accuracy: 0.6612\n",
            "Epoch 32/500\n",
            "44000/44000 [==============================] - 23s 525us/sample - loss: 0.0023 - accuracy: 0.9998 - val_loss: 1.8694 - val_accuracy: 0.6585\n",
            "Epoch 33/500\n",
            "44000/44000 [==============================] - 23s 525us/sample - loss: 0.0022 - accuracy: 0.9998 - val_loss: 1.8723 - val_accuracy: 0.6600\n",
            "Epoch 34/500\n",
            "44000/44000 [==============================] - 23s 524us/sample - loss: 0.0021 - accuracy: 0.9998 - val_loss: 1.8678 - val_accuracy: 0.6688\n",
            "Epoch 35/500\n",
            "44000/44000 [==============================] - 23s 524us/sample - loss: 0.0020 - accuracy: 0.9998 - val_loss: 1.8586 - val_accuracy: 0.6620\n",
            "Epoch 36/500\n",
            "44000/44000 [==============================] - 23s 524us/sample - loss: 0.0015 - accuracy: 0.9999 - val_loss: 1.8710 - val_accuracy: 0.6662\n",
            "Epoch 37/500\n",
            "44000/44000 [==============================] - 23s 525us/sample - loss: 0.0020 - accuracy: 0.9998 - val_loss: 1.8714 - val_accuracy: 0.6645\n",
            "Epoch 38/500\n",
            "44000/44000 [==============================] - 23s 524us/sample - loss: 0.0017 - accuracy: 0.9998 - val_loss: 1.8833 - val_accuracy: 0.6603\n",
            "Epoch 39/500\n",
            "44000/44000 [==============================] - 23s 525us/sample - loss: 0.0014 - accuracy: 0.9999 - val_loss: 1.9203 - val_accuracy: 0.6592\n",
            "Epoch 40/500\n",
            "44000/44000 [==============================] - 23s 525us/sample - loss: 0.0021 - accuracy: 0.9998 - val_loss: 1.9273 - val_accuracy: 0.6593\n",
            "Epoch 41/500\n",
            "44000/44000 [==============================] - 23s 525us/sample - loss: 0.0012 - accuracy: 0.9999 - val_loss: 1.8922 - val_accuracy: 0.6665\n",
            "Epoch 42/500\n",
            "44000/44000 [==============================] - 23s 525us/sample - loss: 0.0015 - accuracy: 0.9999 - val_loss: 1.9227 - val_accuracy: 0.6638\n",
            "Epoch 43/500\n",
            "44000/44000 [==============================] - 23s 524us/sample - loss: 0.0017 - accuracy: 0.9999 - val_loss: 1.9609 - val_accuracy: 0.6560\n",
            "Epoch 44/500\n",
            "44000/44000 [==============================] - 23s 524us/sample - loss: 0.0018 - accuracy: 0.9999 - val_loss: 1.9151 - val_accuracy: 0.6652\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh-8aDjPxn0v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "7644e1b5-3843-4696-8c99-2803697f8d50"
      },
      "source": [
        "# We analyse the result:\n",
        "\n",
        "[train_loss, train_accuracy] = model.evaluate(x_train_small, r_train_small, verbose=0)\n",
        "print(\"Training set Accuracy:{:7.2f}\".format(train_accuracy))\n",
        "print(\"Training set Loss:{:7.4f}\\n\".format(train_loss))\n",
        "\n",
        "[val_loss, val_accuracy] = model.evaluate(x_val, r_val, verbose=0)\n",
        "print(\"Validation set Accuracy:{:7.2f}\".format(val_accuracy))\n",
        "print(\"Validation set Loss:{:7.4f}\\n\".format(val_loss))\n",
        "\n",
        "#Now we visualise what happened during training\n",
        "plot_history(history)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set Accuracy:   1.00\n",
            "Training set Loss: 0.0010\n",
            "\n",
            "Validation set Accuracy:   0.67\n",
            "Validation set Loss: 1.9151\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAEKCAYAAAA7GmJIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzLMM8f03ykG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "023a725d-d8af-488e-c7da-d81f470e26e9"
      },
      "source": [
        "model = complex_model()\n",
        "es_callback = EarlyStopping(monitor='val_accuracy', patience=10, min_delta=0.0001)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=True, samplewise_center=True,\n",
        "    featurewise_std_normalization=True, samplewise_std_normalization=True,\n",
        "    zca_whitening=False, zca_epsilon=1e-06, rotation_range=45, width_shift_range=0.0,\n",
        "    height_shift_range=0.0, brightness_range=None, shear_range=0.0, zoom_range=0.0,\n",
        "    channel_shift_range=0.0, fill_mode='nearest', cval=0.0, horizontal_flip=True,\n",
        "    vertical_flip=True, rescale=None, preprocessing_function=None,\n",
        "    data_format=None, validation_split=0.0, dtype=None\n",
        ")\n",
        "\n",
        "datagen.fit(x_train,augment=True)\n",
        "\n",
        "au_history = model.fit(datagen.flow(\n",
        "    x_train, r_train, batch_size=batch_size, shuffle=True, sample_weight=None, seed=None,\n",
        "    save_to_dir=None, save_prefix='', save_format='png', subset=None),\n",
        "    epochs=epochs, steps_per_epoch=len(x_train) / batch_size,\n",
        "                                    validation_data=(x_val, r_val),\n",
        "                                    callbacks = [es_callback])\n",
        "\n",
        "# We analyse the result:\n",
        "\n",
        "[train_loss, train_accuracy] = model.evaluate(x_train_small, r_train_small, verbose=0)\n",
        "print(\"Training set Accuracy:{:7.2f}\".format(train_accuracy))\n",
        "print(\"Training set Loss:{:7.4f}\\n\".format(train_loss))\n",
        "\n",
        "[val_loss, val_accuracy] = model.evaluate(x_val, r_val, verbose=0)\n",
        "print(\"Validation set Accuracy:{:7.2f}\".format(val_accuracy))\n",
        "print(\"Validation set Loss:{:7.4f}\\n\".format(val_loss))\n",
        "\n",
        "#Now we visualise what happened during training\n",
        "plot_history(au_history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 42.96875 steps, validate on 6000 samples\n",
            "Epoch 1/500\n",
            "43/42 [==============================] - 30s 708ms/step - loss: 2.7358 - accuracy: 0.1812 - val_loss: 5.9902 - val_accuracy: 0.0528\n",
            "Epoch 2/500\n",
            "43/42 [==============================] - 30s 695ms/step - loss: 2.3671 - accuracy: 0.2706 - val_loss: 9.7465 - val_accuracy: 0.0528\n",
            "Epoch 3/500\n",
            "43/42 [==============================] - 30s 688ms/step - loss: 2.1967 - accuracy: 0.3181 - val_loss: 8.3169 - val_accuracy: 0.0528\n",
            "Epoch 4/500\n",
            "43/42 [==============================] - 30s 691ms/step - loss: 2.0536 - accuracy: 0.3572 - val_loss: 11.1019 - val_accuracy: 0.0528\n",
            "Epoch 5/500\n",
            "43/42 [==============================] - 30s 688ms/step - loss: 1.9529 - accuracy: 0.3882 - val_loss: 8.4486 - val_accuracy: 0.0528\n",
            "Epoch 6/500\n",
            "43/42 [==============================] - 30s 691ms/step - loss: 1.8312 - accuracy: 0.4238 - val_loss: 7.3995 - val_accuracy: 0.0528\n",
            "Epoch 7/500\n",
            "43/42 [==============================] - 29s 680ms/step - loss: 1.7503 - accuracy: 0.4472 - val_loss: 8.9410 - val_accuracy: 0.0528\n",
            "Epoch 8/500\n",
            "43/42 [==============================] - 30s 691ms/step - loss: 1.6717 - accuracy: 0.4709 - val_loss: 8.3580 - val_accuracy: 0.0528\n",
            "Epoch 9/500\n",
            "43/42 [==============================] - 30s 687ms/step - loss: 1.6138 - accuracy: 0.4857 - val_loss: 8.3081 - val_accuracy: 0.0528\n",
            "Epoch 10/500\n",
            "43/42 [==============================] - 30s 693ms/step - loss: 1.5448 - accuracy: 0.5085 - val_loss: 7.7574 - val_accuracy: 0.0528\n",
            "Epoch 11/500\n",
            "43/42 [==============================] - 30s 688ms/step - loss: 1.5111 - accuracy: 0.5210 - val_loss: 7.1961 - val_accuracy: 0.0530\n",
            "Epoch 12/500\n",
            "43/42 [==============================] - 30s 688ms/step - loss: 1.4631 - accuracy: 0.5354 - val_loss: 7.4401 - val_accuracy: 0.0528\n",
            "Epoch 13/500\n",
            "43/42 [==============================] - 30s 689ms/step - loss: 1.4316 - accuracy: 0.5425 - val_loss: 9.4305 - val_accuracy: 0.0528\n",
            "Epoch 14/500\n",
            "43/42 [==============================] - 30s 691ms/step - loss: 1.3990 - accuracy: 0.5538 - val_loss: 9.8161 - val_accuracy: 0.0528\n",
            "Epoch 15/500\n",
            "15/42 [=========>....................] - ETA: 19s - loss: 1.3596 - accuracy: 0.5658"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-9GVYK53yxn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_dual_history(before,after):\n",
        "  plt.figure(figsize = (20,6))\n",
        "  plt.subplot(1,2,1)\n",
        "\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.plot(before.epoch, np.array(before.history['accuracy']),'g-',\n",
        "           label='Initial train accuracy')\n",
        "  plt.plot(after.epoch, np.array(after.history['accuracy']),'g:',\n",
        "           label='Final train accuracy')\n",
        "  plt.plot(before.epoch, np.array(before.history['val_accuracy']),'r-',\n",
        "           label = 'Initial validation accuracy')\n",
        "  plt.plot(after.epoch, np.array(after.history['val_accuracy']),'r:',\n",
        "           label = 'Final validation accuracy')\n",
        "  plt.ylim([0.0,1.0])\n",
        "  plt.legend()\n",
        "\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss minimised by model')\n",
        "  plt.plot(before.epoch, np.array(before.history['loss']),'g-',\n",
        "           label='Initial train loss')\n",
        "  plt.plot(after.epoch, np.array(after.history['loss']),'g:',\n",
        "           label='Final train loss')\n",
        "  plt.plot(before.epoch, np.array(before.history['val_loss']),'r-',\n",
        "           label = 'Initial validation loss')\n",
        "  plt.plot(after.epoch, np.array(after.history['val_loss']),'r:',\n",
        "           label = 'Final validation loss')\n",
        "  plt.legend()\n",
        "\n",
        "\n",
        "plot_dual_history(history,au_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_46kM2p73yvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYcrG3qc3ytp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70FVGsb43ysW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jD0cgHh3ypP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Xk7vUpf6rMz",
        "colab_type": "code",
        "outputId": "9b7aa2f8-f8dd-48d2-da51-e85541c11ab8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Grid search number of conv and dense blocks\n",
        "conv_blocks = range(1,6)\n",
        "dense_blocks = range(1,6)\n",
        "accuracies = [[]]\n",
        "losses = [[]]\n",
        "\n",
        "for nb_conv in conv_blocks:\n",
        "  conv_acc = [[]]\n",
        "  conv_loss = [[]]\n",
        "  for nb_dense in dense_blocks:\n",
        "    model = complex_model(nb_conv,nb_dense)\n",
        "    model.fit(x_train, r_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_val, r_val),\n",
        "          shuffle=True)\n",
        "    [val_loss, val_accuracy] = model.evaluate(x_val, r_val, verbose=0)\n",
        "    conv_acc = np.append(conv_acc,[[val_accuracy]],axis=1)\n",
        "    conv_loss = np.append(conv_loss,[[val_loss]],axis=1)\n",
        "  accuracies = np.append(accuracies,conv_acc)\n",
        "  losses = np.append(losses,conv_loss)\n",
        "\n",
        "index_acc = np.unravel_index(np.argmax(accuracies, axis=None), accuracies.shape)\n",
        "index_loss = np.unravel_index(np.argmin(losses,axis=None), losses.shape)\n",
        "best_acc = accuracies[index_acc]\n",
        "best_loss = losses[index_loss]\n",
        "\n",
        "print(f'Best acc of {best_acc} for {index_acc}')\n",
        "print(f'Best loss of {best_loss} for {index_loss}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 2.8782 - accuracy: 0.0896 - val_loss: 2.6880 - val_accuracy: 0.1482\n",
            "Epoch 2/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 2.5911 - accuracy: 0.1821 - val_loss: 2.4853 - val_accuracy: 0.2170\n",
            "Epoch 3/50\n",
            "44000/44000 [==============================] - 3s 57us/sample - loss: 2.4083 - accuracy: 0.2473 - val_loss: 2.3255 - val_accuracy: 0.2705\n",
            "Epoch 4/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 2.2530 - accuracy: 0.2976 - val_loss: 2.1618 - val_accuracy: 0.3162\n",
            "Epoch 5/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 2.1100 - accuracy: 0.3379 - val_loss: 2.1009 - val_accuracy: 0.3352\n",
            "Epoch 6/50\n",
            "44000/44000 [==============================] - 3s 57us/sample - loss: 2.0048 - accuracy: 0.3715 - val_loss: 1.9401 - val_accuracy: 0.3858\n",
            "Epoch 7/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 1.9002 - accuracy: 0.4020 - val_loss: 1.8594 - val_accuracy: 0.4103\n",
            "Epoch 8/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 1.7859 - accuracy: 0.4372 - val_loss: 1.8192 - val_accuracy: 0.4337\n",
            "Epoch 9/50\n",
            "44000/44000 [==============================] - 3s 57us/sample - loss: 1.6954 - accuracy: 0.4655 - val_loss: 1.7905 - val_accuracy: 0.4447\n",
            "Epoch 10/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 1.6053 - accuracy: 0.4933 - val_loss: 1.7449 - val_accuracy: 0.4592\n",
            "Epoch 11/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 1.5131 - accuracy: 0.5190 - val_loss: 1.6598 - val_accuracy: 0.4813\n",
            "Epoch 12/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 1.4163 - accuracy: 0.5480 - val_loss: 1.6602 - val_accuracy: 0.4867\n",
            "Epoch 13/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 1.3195 - accuracy: 0.5797 - val_loss: 1.6368 - val_accuracy: 0.4932\n",
            "Epoch 14/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 1.2421 - accuracy: 0.6021 - val_loss: 1.6000 - val_accuracy: 0.5072\n",
            "Epoch 15/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 1.1252 - accuracy: 0.6381 - val_loss: 1.6012 - val_accuracy: 0.5173\n",
            "Epoch 16/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 1.0268 - accuracy: 0.6704 - val_loss: 1.6643 - val_accuracy: 0.5125\n",
            "Epoch 17/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.9182 - accuracy: 0.7034 - val_loss: 1.7652 - val_accuracy: 0.5088\n",
            "Epoch 18/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.8030 - accuracy: 0.7366 - val_loss: 1.7759 - val_accuracy: 0.5180\n",
            "Epoch 19/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.6683 - accuracy: 0.7809 - val_loss: 1.8782 - val_accuracy: 0.5097\n",
            "Epoch 20/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.5857 - accuracy: 0.8056 - val_loss: 2.0318 - val_accuracy: 0.5113\n",
            "Epoch 21/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.4368 - accuracy: 0.8559 - val_loss: 2.1845 - val_accuracy: 0.5178\n",
            "Epoch 22/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.3390 - accuracy: 0.8877 - val_loss: 2.4153 - val_accuracy: 0.5003\n",
            "Epoch 23/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.3023 - accuracy: 0.8982 - val_loss: 2.7689 - val_accuracy: 0.4978\n",
            "Epoch 24/50\n",
            "44000/44000 [==============================] - 3s 57us/sample - loss: 0.2291 - accuracy: 0.9233 - val_loss: 2.8217 - val_accuracy: 0.5065\n",
            "Epoch 25/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.1955 - accuracy: 0.9333 - val_loss: 3.1223 - val_accuracy: 0.5065\n",
            "Epoch 26/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.1644 - accuracy: 0.9457 - val_loss: 2.9701 - val_accuracy: 0.5128\n",
            "Epoch 27/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.1274 - accuracy: 0.9584 - val_loss: 3.4320 - val_accuracy: 0.5102\n",
            "Epoch 28/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.1009 - accuracy: 0.9672 - val_loss: 3.6422 - val_accuracy: 0.5108\n",
            "Epoch 29/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.1005 - accuracy: 0.9659 - val_loss: 3.6379 - val_accuracy: 0.5057\n",
            "Epoch 30/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.0878 - accuracy: 0.9716 - val_loss: 3.8364 - val_accuracy: 0.5073\n",
            "Epoch 31/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.0931 - accuracy: 0.9678 - val_loss: 3.7026 - val_accuracy: 0.5075\n",
            "Epoch 32/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.0884 - accuracy: 0.9705 - val_loss: 3.8871 - val_accuracy: 0.5030\n",
            "Epoch 33/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.0653 - accuracy: 0.9786 - val_loss: 4.2493 - val_accuracy: 0.5110\n",
            "Epoch 34/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.0613 - accuracy: 0.9795 - val_loss: 4.0227 - val_accuracy: 0.5068\n",
            "Epoch 35/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.0608 - accuracy: 0.9802 - val_loss: 4.1127 - val_accuracy: 0.5043\n",
            "Epoch 36/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.0630 - accuracy: 0.9798 - val_loss: 4.1040 - val_accuracy: 0.4948\n",
            "Epoch 37/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.0496 - accuracy: 0.9839 - val_loss: 4.4529 - val_accuracy: 0.5082\n",
            "Epoch 38/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.0563 - accuracy: 0.9821 - val_loss: 4.2298 - val_accuracy: 0.5073\n",
            "Epoch 39/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.0680 - accuracy: 0.9776 - val_loss: 3.9852 - val_accuracy: 0.5065\n",
            "Epoch 40/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.0793 - accuracy: 0.9727 - val_loss: 4.0598 - val_accuracy: 0.5112\n",
            "Epoch 41/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.0601 - accuracy: 0.9807 - val_loss: 4.0632 - val_accuracy: 0.5123\n",
            "Epoch 42/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.0494 - accuracy: 0.9842 - val_loss: 4.1067 - val_accuracy: 0.5157\n",
            "Epoch 43/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.0553 - accuracy: 0.9820 - val_loss: 4.0822 - val_accuracy: 0.5040\n",
            "Epoch 44/50\n",
            "44000/44000 [==============================] - 3s 57us/sample - loss: 0.0634 - accuracy: 0.9787 - val_loss: 4.1971 - val_accuracy: 0.5037\n",
            "Epoch 45/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.0350 - accuracy: 0.9892 - val_loss: 4.6170 - val_accuracy: 0.5117\n",
            "Epoch 46/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.0380 - accuracy: 0.9882 - val_loss: 4.3975 - val_accuracy: 0.5088\n",
            "Epoch 47/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0647 - accuracy: 0.9782 - val_loss: 4.3023 - val_accuracy: 0.5130\n",
            "Epoch 48/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.0400 - accuracy: 0.9872 - val_loss: 4.5237 - val_accuracy: 0.5085\n",
            "Epoch 49/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.0422 - accuracy: 0.9862 - val_loss: 4.7610 - val_accuracy: 0.5138\n",
            "Epoch 50/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.0422 - accuracy: 0.9873 - val_loss: 4.6401 - val_accuracy: 0.5007\n",
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.8673 - accuracy: 0.0978 - val_loss: 2.6863 - val_accuracy: 0.1455\n",
            "Epoch 2/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 2.6318 - accuracy: 0.1703 - val_loss: 2.6082 - val_accuracy: 0.1792\n",
            "Epoch 3/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 2.5028 - accuracy: 0.2165 - val_loss: 2.3800 - val_accuracy: 0.2567\n",
            "Epoch 4/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 2.3290 - accuracy: 0.2697 - val_loss: 2.2398 - val_accuracy: 0.2978\n",
            "Epoch 5/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 2.1857 - accuracy: 0.3154 - val_loss: 2.1385 - val_accuracy: 0.3298\n",
            "Epoch 6/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 2.0702 - accuracy: 0.3490 - val_loss: 2.0227 - val_accuracy: 0.3665\n",
            "Epoch 7/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 1.9607 - accuracy: 0.3836 - val_loss: 1.9343 - val_accuracy: 0.3937\n",
            "Epoch 8/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 1.8524 - accuracy: 0.4166 - val_loss: 1.8484 - val_accuracy: 0.4125\n",
            "Epoch 9/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 1.7645 - accuracy: 0.4402 - val_loss: 1.7743 - val_accuracy: 0.4363\n",
            "Epoch 10/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 1.6403 - accuracy: 0.4792 - val_loss: 1.7485 - val_accuracy: 0.4520\n",
            "Epoch 11/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 1.5841 - accuracy: 0.4960 - val_loss: 1.6971 - val_accuracy: 0.4712\n",
            "Epoch 12/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 1.4715 - accuracy: 0.5284 - val_loss: 1.6342 - val_accuracy: 0.4952\n",
            "Epoch 13/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 1.3759 - accuracy: 0.5558 - val_loss: 1.6070 - val_accuracy: 0.4970\n",
            "Epoch 14/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 1.2905 - accuracy: 0.5843 - val_loss: 1.5903 - val_accuracy: 0.5018\n",
            "Epoch 15/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 1.2078 - accuracy: 0.6103 - val_loss: 1.5625 - val_accuracy: 0.5143\n",
            "Epoch 16/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 1.1061 - accuracy: 0.6416 - val_loss: 1.6120 - val_accuracy: 0.5210\n",
            "Epoch 17/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 1.0121 - accuracy: 0.6697 - val_loss: 1.6219 - val_accuracy: 0.5227\n",
            "Epoch 18/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.9153 - accuracy: 0.7002 - val_loss: 1.6946 - val_accuracy: 0.5132\n",
            "Epoch 19/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.7985 - accuracy: 0.7369 - val_loss: 1.7279 - val_accuracy: 0.5197\n",
            "Epoch 20/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.7214 - accuracy: 0.7598 - val_loss: 1.8130 - val_accuracy: 0.5183\n",
            "Epoch 21/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.6158 - accuracy: 0.7941 - val_loss: 1.8771 - val_accuracy: 0.5327\n",
            "Epoch 22/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.5213 - accuracy: 0.8235 - val_loss: 2.0596 - val_accuracy: 0.5293\n",
            "Epoch 23/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.4124 - accuracy: 0.8609 - val_loss: 2.1857 - val_accuracy: 0.5148\n",
            "Epoch 24/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.3356 - accuracy: 0.8852 - val_loss: 2.4503 - val_accuracy: 0.5140\n",
            "Epoch 25/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.3191 - accuracy: 0.8916 - val_loss: 2.4711 - val_accuracy: 0.5267\n",
            "Epoch 26/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.2174 - accuracy: 0.9267 - val_loss: 2.6430 - val_accuracy: 0.5145\n",
            "Epoch 27/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.1891 - accuracy: 0.9365 - val_loss: 2.9186 - val_accuracy: 0.5137\n",
            "Epoch 28/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.2099 - accuracy: 0.9277 - val_loss: 2.7699 - val_accuracy: 0.5048\n",
            "Epoch 29/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.1655 - accuracy: 0.9431 - val_loss: 3.2382 - val_accuracy: 0.5260\n",
            "Epoch 30/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.1044 - accuracy: 0.9647 - val_loss: 3.4278 - val_accuracy: 0.5203\n",
            "Epoch 31/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.0918 - accuracy: 0.9700 - val_loss: 3.5199 - val_accuracy: 0.5248\n",
            "Epoch 32/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.1125 - accuracy: 0.9615 - val_loss: 3.5002 - val_accuracy: 0.5185\n",
            "Epoch 33/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.1079 - accuracy: 0.9628 - val_loss: 3.4850 - val_accuracy: 0.5220\n",
            "Epoch 34/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.1297 - accuracy: 0.9570 - val_loss: 3.1922 - val_accuracy: 0.4918\n",
            "Epoch 35/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.1344 - accuracy: 0.9557 - val_loss: 3.5164 - val_accuracy: 0.5252\n",
            "Epoch 36/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.0602 - accuracy: 0.9807 - val_loss: 3.8232 - val_accuracy: 0.5172\n",
            "Epoch 37/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.0615 - accuracy: 0.9790 - val_loss: 3.7829 - val_accuracy: 0.5233\n",
            "Epoch 38/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0807 - accuracy: 0.9732 - val_loss: 3.7176 - val_accuracy: 0.5153\n",
            "Epoch 39/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.0735 - accuracy: 0.9771 - val_loss: 3.7917 - val_accuracy: 0.5233\n",
            "Epoch 40/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.0562 - accuracy: 0.9819 - val_loss: 3.9278 - val_accuracy: 0.5258\n",
            "Epoch 41/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.0585 - accuracy: 0.9813 - val_loss: 3.9231 - val_accuracy: 0.5237\n",
            "Epoch 42/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0549 - accuracy: 0.9819 - val_loss: 4.1516 - val_accuracy: 0.5272\n",
            "Epoch 43/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0587 - accuracy: 0.9811 - val_loss: 3.9845 - val_accuracy: 0.5242\n",
            "Epoch 44/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0595 - accuracy: 0.9797 - val_loss: 4.0217 - val_accuracy: 0.5155\n",
            "Epoch 45/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0509 - accuracy: 0.9829 - val_loss: 4.1157 - val_accuracy: 0.5247\n",
            "Epoch 46/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.0548 - accuracy: 0.9821 - val_loss: 3.8377 - val_accuracy: 0.5238\n",
            "Epoch 47/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0551 - accuracy: 0.9819 - val_loss: 4.0213 - val_accuracy: 0.5217\n",
            "Epoch 48/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0688 - accuracy: 0.9772 - val_loss: 4.0669 - val_accuracy: 0.5220\n",
            "Epoch 49/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0711 - accuracy: 0.9770 - val_loss: 3.7361 - val_accuracy: 0.5200\n",
            "Epoch 50/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.0714 - accuracy: 0.9766 - val_loss: 3.7752 - val_accuracy: 0.5232\n",
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.8904 - accuracy: 0.0932 - val_loss: 2.7120 - val_accuracy: 0.1312\n",
            "Epoch 2/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 2.6353 - accuracy: 0.1618 - val_loss: 2.4998 - val_accuracy: 0.2068\n",
            "Epoch 3/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 2.4694 - accuracy: 0.2204 - val_loss: 2.4238 - val_accuracy: 0.2313\n",
            "Epoch 4/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 2.3496 - accuracy: 0.2624 - val_loss: 2.3038 - val_accuracy: 0.2708\n",
            "Epoch 5/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 2.2207 - accuracy: 0.2997 - val_loss: 2.1452 - val_accuracy: 0.3222\n",
            "Epoch 6/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 2.0976 - accuracy: 0.3390 - val_loss: 2.0369 - val_accuracy: 0.3528\n",
            "Epoch 7/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 1.9966 - accuracy: 0.3736 - val_loss: 1.9457 - val_accuracy: 0.3793\n",
            "Epoch 8/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 1.8613 - accuracy: 0.4123 - val_loss: 1.8381 - val_accuracy: 0.4208\n",
            "Epoch 9/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 1.7748 - accuracy: 0.4385 - val_loss: 1.8612 - val_accuracy: 0.4193\n",
            "Epoch 10/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 1.6683 - accuracy: 0.4692 - val_loss: 1.7729 - val_accuracy: 0.4505\n",
            "Epoch 11/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 1.5298 - accuracy: 0.5117 - val_loss: 1.7175 - val_accuracy: 0.4585\n",
            "Epoch 12/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 1.4416 - accuracy: 0.5390 - val_loss: 1.6844 - val_accuracy: 0.4792\n",
            "Epoch 13/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 1.3259 - accuracy: 0.5738 - val_loss: 1.6895 - val_accuracy: 0.4790\n",
            "Epoch 14/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 1.2150 - accuracy: 0.6087 - val_loss: 1.7135 - val_accuracy: 0.4820\n",
            "Epoch 15/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 1.0843 - accuracy: 0.6508 - val_loss: 1.7358 - val_accuracy: 0.4852\n",
            "Epoch 16/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.9544 - accuracy: 0.6902 - val_loss: 1.7901 - val_accuracy: 0.4915\n",
            "Epoch 17/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.8539 - accuracy: 0.7213 - val_loss: 1.8591 - val_accuracy: 0.4878\n",
            "Epoch 18/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.6911 - accuracy: 0.7720 - val_loss: 2.0368 - val_accuracy: 0.4873\n",
            "Epoch 19/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.5811 - accuracy: 0.8042 - val_loss: 2.1693 - val_accuracy: 0.4947\n",
            "Epoch 20/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.5090 - accuracy: 0.8301 - val_loss: 2.1741 - val_accuracy: 0.4885\n",
            "Epoch 21/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.4384 - accuracy: 0.8518 - val_loss: 2.4284 - val_accuracy: 0.4853\n",
            "Epoch 22/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.3570 - accuracy: 0.8784 - val_loss: 2.6255 - val_accuracy: 0.4923\n",
            "Epoch 23/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.2943 - accuracy: 0.8991 - val_loss: 2.7215 - val_accuracy: 0.4852\n",
            "Epoch 24/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.2492 - accuracy: 0.9162 - val_loss: 2.9590 - val_accuracy: 0.4900\n",
            "Epoch 25/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.1976 - accuracy: 0.9334 - val_loss: 3.1040 - val_accuracy: 0.4877\n",
            "Epoch 26/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.1716 - accuracy: 0.9407 - val_loss: 3.1767 - val_accuracy: 0.4940\n",
            "Epoch 27/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.1414 - accuracy: 0.9515 - val_loss: 3.4134 - val_accuracy: 0.4942\n",
            "Epoch 28/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.1492 - accuracy: 0.9505 - val_loss: 3.3455 - val_accuracy: 0.5000\n",
            "Epoch 29/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.1380 - accuracy: 0.9530 - val_loss: 3.3614 - val_accuracy: 0.4960\n",
            "Epoch 30/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.1221 - accuracy: 0.9588 - val_loss: 3.5517 - val_accuracy: 0.4872\n",
            "Epoch 31/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.1170 - accuracy: 0.9607 - val_loss: 3.7895 - val_accuracy: 0.5022\n",
            "Epoch 32/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.1061 - accuracy: 0.9645 - val_loss: 3.6407 - val_accuracy: 0.4963\n",
            "Epoch 33/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.1006 - accuracy: 0.9664 - val_loss: 3.7318 - val_accuracy: 0.5010\n",
            "Epoch 34/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0781 - accuracy: 0.9743 - val_loss: 4.0881 - val_accuracy: 0.5068\n",
            "Epoch 35/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0773 - accuracy: 0.9745 - val_loss: 4.0028 - val_accuracy: 0.4982\n",
            "Epoch 36/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.0778 - accuracy: 0.9743 - val_loss: 3.9707 - val_accuracy: 0.4947\n",
            "Epoch 37/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0888 - accuracy: 0.9710 - val_loss: 3.7345 - val_accuracy: 0.4973\n",
            "Epoch 38/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0976 - accuracy: 0.9670 - val_loss: 3.8483 - val_accuracy: 0.4987\n",
            "Epoch 39/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0760 - accuracy: 0.9745 - val_loss: 3.8950 - val_accuracy: 0.4970\n",
            "Epoch 40/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.0832 - accuracy: 0.9732 - val_loss: 3.7389 - val_accuracy: 0.4932\n",
            "Epoch 41/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0826 - accuracy: 0.9728 - val_loss: 3.9089 - val_accuracy: 0.5017\n",
            "Epoch 42/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0711 - accuracy: 0.9768 - val_loss: 3.8326 - val_accuracy: 0.5085\n",
            "Epoch 43/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0563 - accuracy: 0.9816 - val_loss: 4.1692 - val_accuracy: 0.5065\n",
            "Epoch 44/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0641 - accuracy: 0.9781 - val_loss: 3.9457 - val_accuracy: 0.4975\n",
            "Epoch 45/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0620 - accuracy: 0.9797 - val_loss: 3.8144 - val_accuracy: 0.5022\n",
            "Epoch 46/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0460 - accuracy: 0.9846 - val_loss: 4.3364 - val_accuracy: 0.4980\n",
            "Epoch 47/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0679 - accuracy: 0.9784 - val_loss: 4.0202 - val_accuracy: 0.5013\n",
            "Epoch 48/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0672 - accuracy: 0.9775 - val_loss: 4.1182 - val_accuracy: 0.5003\n",
            "Epoch 49/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0565 - accuracy: 0.9812 - val_loss: 3.9893 - val_accuracy: 0.5032\n",
            "Epoch 50/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.0491 - accuracy: 0.9839 - val_loss: 4.2712 - val_accuracy: 0.5132\n",
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "44000/44000 [==============================] - 3s 78us/sample - loss: 2.9133 - accuracy: 0.0784 - val_loss: 2.7560 - val_accuracy: 0.1072\n",
            "Epoch 2/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 2.7411 - accuracy: 0.1317 - val_loss: 2.6707 - val_accuracy: 0.1532\n",
            "Epoch 3/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 2.5831 - accuracy: 0.1829 - val_loss: 2.4624 - val_accuracy: 0.2212\n",
            "Epoch 4/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 2.4406 - accuracy: 0.2277 - val_loss: 2.3846 - val_accuracy: 0.2355\n",
            "Epoch 5/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 2.3548 - accuracy: 0.2568 - val_loss: 2.2798 - val_accuracy: 0.2860\n",
            "Epoch 6/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 2.2465 - accuracy: 0.2895 - val_loss: 2.2463 - val_accuracy: 0.2923\n",
            "Epoch 7/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 2.1598 - accuracy: 0.3180 - val_loss: 2.1156 - val_accuracy: 0.3310\n",
            "Epoch 8/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 2.0526 - accuracy: 0.3524 - val_loss: 2.0005 - val_accuracy: 0.3675\n",
            "Epoch 9/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 1.9333 - accuracy: 0.3853 - val_loss: 1.9349 - val_accuracy: 0.3825\n",
            "Epoch 10/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 1.8589 - accuracy: 0.4088 - val_loss: 1.9423 - val_accuracy: 0.3845\n",
            "Epoch 11/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 1.7581 - accuracy: 0.4430 - val_loss: 1.8749 - val_accuracy: 0.4085\n",
            "Epoch 12/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 1.6491 - accuracy: 0.4765 - val_loss: 1.8202 - val_accuracy: 0.4232\n",
            "Epoch 13/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 1.5379 - accuracy: 0.5099 - val_loss: 1.7903 - val_accuracy: 0.4435\n",
            "Epoch 14/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 1.4167 - accuracy: 0.5449 - val_loss: 1.7972 - val_accuracy: 0.4518\n",
            "Epoch 15/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 1.3159 - accuracy: 0.5767 - val_loss: 1.7633 - val_accuracy: 0.4737\n",
            "Epoch 16/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 1.1927 - accuracy: 0.6127 - val_loss: 1.7937 - val_accuracy: 0.4662\n",
            "Epoch 17/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 1.0744 - accuracy: 0.6522 - val_loss: 1.8594 - val_accuracy: 0.4692\n",
            "Epoch 18/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.9540 - accuracy: 0.6871 - val_loss: 1.9273 - val_accuracy: 0.4758\n",
            "Epoch 19/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.8291 - accuracy: 0.7265 - val_loss: 2.0759 - val_accuracy: 0.4700\n",
            "Epoch 20/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.7327 - accuracy: 0.7599 - val_loss: 2.2068 - val_accuracy: 0.4752\n",
            "Epoch 21/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.6334 - accuracy: 0.7911 - val_loss: 2.3369 - val_accuracy: 0.4555\n",
            "Epoch 22/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.5450 - accuracy: 0.8201 - val_loss: 2.4743 - val_accuracy: 0.4547\n",
            "Epoch 23/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.4848 - accuracy: 0.8395 - val_loss: 2.5048 - val_accuracy: 0.4627\n",
            "Epoch 24/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.4112 - accuracy: 0.8632 - val_loss: 2.7748 - val_accuracy: 0.4668\n",
            "Epoch 25/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.3408 - accuracy: 0.8876 - val_loss: 2.7735 - val_accuracy: 0.4725\n",
            "Epoch 26/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.3025 - accuracy: 0.8992 - val_loss: 2.8873 - val_accuracy: 0.4648\n",
            "Epoch 27/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.2655 - accuracy: 0.9114 - val_loss: 3.1895 - val_accuracy: 0.4607\n",
            "Epoch 28/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.2422 - accuracy: 0.9177 - val_loss: 3.1293 - val_accuracy: 0.4627\n",
            "Epoch 29/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.2363 - accuracy: 0.9208 - val_loss: 3.1481 - val_accuracy: 0.4577\n",
            "Epoch 30/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.1996 - accuracy: 0.9320 - val_loss: 3.2952 - val_accuracy: 0.4583\n",
            "Epoch 31/50\n",
            "44000/44000 [==============================] - 3s 58us/sample - loss: 0.1709 - accuracy: 0.9427 - val_loss: 3.5580 - val_accuracy: 0.4673\n",
            "Epoch 32/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.1690 - accuracy: 0.9431 - val_loss: 3.5000 - val_accuracy: 0.4648\n",
            "Epoch 33/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.1596 - accuracy: 0.9462 - val_loss: 3.4983 - val_accuracy: 0.4667\n",
            "Epoch 34/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.1395 - accuracy: 0.9533 - val_loss: 3.4914 - val_accuracy: 0.4682\n",
            "Epoch 35/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.1486 - accuracy: 0.9505 - val_loss: 3.6374 - val_accuracy: 0.4632\n",
            "Epoch 36/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.1187 - accuracy: 0.9593 - val_loss: 3.8391 - val_accuracy: 0.4633\n",
            "Epoch 37/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0992 - accuracy: 0.9660 - val_loss: 4.0338 - val_accuracy: 0.4603\n",
            "Epoch 38/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.1118 - accuracy: 0.9620 - val_loss: 3.9100 - val_accuracy: 0.4587\n",
            "Epoch 39/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0963 - accuracy: 0.9676 - val_loss: 4.1267 - val_accuracy: 0.4675\n",
            "Epoch 40/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0794 - accuracy: 0.9736 - val_loss: 4.1315 - val_accuracy: 0.4660\n",
            "Epoch 41/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0879 - accuracy: 0.9699 - val_loss: 4.2210 - val_accuracy: 0.4575\n",
            "Epoch 42/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.0962 - accuracy: 0.9683 - val_loss: 3.9356 - val_accuracy: 0.4740\n",
            "Epoch 43/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0952 - accuracy: 0.9688 - val_loss: 3.9406 - val_accuracy: 0.4713\n",
            "Epoch 44/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0946 - accuracy: 0.9689 - val_loss: 3.8824 - val_accuracy: 0.4677\n",
            "Epoch 45/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0705 - accuracy: 0.9777 - val_loss: 4.1999 - val_accuracy: 0.4665\n",
            "Epoch 46/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0667 - accuracy: 0.9781 - val_loss: 4.2826 - val_accuracy: 0.4705\n",
            "Epoch 47/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0886 - accuracy: 0.9709 - val_loss: 3.9443 - val_accuracy: 0.4675\n",
            "Epoch 48/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.0608 - accuracy: 0.9801 - val_loss: 4.3221 - val_accuracy: 0.4632\n",
            "Epoch 49/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0937 - accuracy: 0.9689 - val_loss: 3.9167 - val_accuracy: 0.4645\n",
            "Epoch 50/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0654 - accuracy: 0.9785 - val_loss: 4.1013 - val_accuracy: 0.4715\n",
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "44000/44000 [==============================] - 4s 85us/sample - loss: 2.9887 - accuracy: 0.0535 - val_loss: 2.9762 - val_accuracy: 0.0555\n",
            "Epoch 2/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 2.8544 - accuracy: 0.0909 - val_loss: 2.7352 - val_accuracy: 0.1192\n",
            "Epoch 3/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 2.6701 - accuracy: 0.1436 - val_loss: 2.5464 - val_accuracy: 0.1845\n",
            "Epoch 4/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 2.5337 - accuracy: 0.1968 - val_loss: 2.4604 - val_accuracy: 0.2167\n",
            "Epoch 5/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 2.4481 - accuracy: 0.2230 - val_loss: 2.3701 - val_accuracy: 0.2407\n",
            "Epoch 6/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 2.3632 - accuracy: 0.2545 - val_loss: 2.3036 - val_accuracy: 0.2735\n",
            "Epoch 7/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 2.2588 - accuracy: 0.2860 - val_loss: 2.2702 - val_accuracy: 0.2887\n",
            "Epoch 8/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 2.1742 - accuracy: 0.3164 - val_loss: 2.1608 - val_accuracy: 0.3155\n",
            "Epoch 9/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 2.0614 - accuracy: 0.3498 - val_loss: 2.0426 - val_accuracy: 0.3613\n",
            "Epoch 10/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 1.9673 - accuracy: 0.3789 - val_loss: 2.0006 - val_accuracy: 0.3807\n",
            "Epoch 11/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 1.8794 - accuracy: 0.4039 - val_loss: 1.9346 - val_accuracy: 0.3997\n",
            "Epoch 12/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 1.7923 - accuracy: 0.4337 - val_loss: 1.8818 - val_accuracy: 0.4150\n",
            "Epoch 13/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 1.6832 - accuracy: 0.4655 - val_loss: 1.9355 - val_accuracy: 0.4138\n",
            "Epoch 14/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 1.5900 - accuracy: 0.4944 - val_loss: 1.8401 - val_accuracy: 0.4423\n",
            "Epoch 15/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 1.4678 - accuracy: 0.5303 - val_loss: 1.8605 - val_accuracy: 0.4392\n",
            "Epoch 16/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 1.3763 - accuracy: 0.5546 - val_loss: 1.8622 - val_accuracy: 0.4455\n",
            "Epoch 17/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 1.2538 - accuracy: 0.5946 - val_loss: 1.9107 - val_accuracy: 0.4502\n",
            "Epoch 18/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 1.1271 - accuracy: 0.6313 - val_loss: 1.9451 - val_accuracy: 0.4495\n",
            "Epoch 19/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 1.0135 - accuracy: 0.6679 - val_loss: 2.1261 - val_accuracy: 0.4562\n",
            "Epoch 20/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.9237 - accuracy: 0.6955 - val_loss: 2.2362 - val_accuracy: 0.4322\n",
            "Epoch 21/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.8049 - accuracy: 0.7306 - val_loss: 2.2238 - val_accuracy: 0.4493\n",
            "Epoch 22/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.6856 - accuracy: 0.7723 - val_loss: 2.4541 - val_accuracy: 0.4553\n",
            "Epoch 23/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.6257 - accuracy: 0.7926 - val_loss: 2.5266 - val_accuracy: 0.4507\n",
            "Epoch 24/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.5335 - accuracy: 0.8225 - val_loss: 2.8091 - val_accuracy: 0.4483\n",
            "Epoch 25/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.4678 - accuracy: 0.8455 - val_loss: 2.8217 - val_accuracy: 0.4468\n",
            "Epoch 26/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.4023 - accuracy: 0.8659 - val_loss: 3.0996 - val_accuracy: 0.4380\n",
            "Epoch 27/50\n",
            "44000/44000 [==============================] - 3s 61us/sample - loss: 0.3857 - accuracy: 0.8690 - val_loss: 3.2308 - val_accuracy: 0.4458\n",
            "Epoch 28/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.3012 - accuracy: 0.8998 - val_loss: 3.4710 - val_accuracy: 0.4463\n",
            "Epoch 29/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.2899 - accuracy: 0.9024 - val_loss: 3.4067 - val_accuracy: 0.4558\n",
            "Epoch 30/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.2486 - accuracy: 0.9161 - val_loss: 3.4193 - val_accuracy: 0.4487\n",
            "Epoch 31/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.2155 - accuracy: 0.9279 - val_loss: 3.8984 - val_accuracy: 0.4412\n",
            "Epoch 32/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.2139 - accuracy: 0.9285 - val_loss: 3.7086 - val_accuracy: 0.4503\n",
            "Epoch 33/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.2261 - accuracy: 0.9243 - val_loss: 3.4788 - val_accuracy: 0.4402\n",
            "Epoch 34/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.2074 - accuracy: 0.9303 - val_loss: 3.7833 - val_accuracy: 0.4523\n",
            "Epoch 35/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.1626 - accuracy: 0.9457 - val_loss: 3.9841 - val_accuracy: 0.4447\n",
            "Epoch 36/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.1387 - accuracy: 0.9547 - val_loss: 4.0708 - val_accuracy: 0.4588\n",
            "Epoch 37/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.1196 - accuracy: 0.9612 - val_loss: 4.3860 - val_accuracy: 0.4450\n",
            "Epoch 38/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.1220 - accuracy: 0.9609 - val_loss: 4.3118 - val_accuracy: 0.4567\n",
            "Epoch 39/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.1277 - accuracy: 0.9589 - val_loss: 4.0146 - val_accuracy: 0.4495\n",
            "Epoch 40/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.1250 - accuracy: 0.9592 - val_loss: 4.2322 - val_accuracy: 0.4623\n",
            "Epoch 41/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.0909 - accuracy: 0.9701 - val_loss: 4.3656 - val_accuracy: 0.4550\n",
            "Epoch 42/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.1041 - accuracy: 0.9666 - val_loss: 4.4728 - val_accuracy: 0.4543\n",
            "Epoch 43/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.1084 - accuracy: 0.9652 - val_loss: 4.2898 - val_accuracy: 0.4523\n",
            "Epoch 44/50\n",
            "44000/44000 [==============================] - 3s 60us/sample - loss: 0.0907 - accuracy: 0.9703 - val_loss: 4.6204 - val_accuracy: 0.4547\n",
            "Epoch 45/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0752 - accuracy: 0.9747 - val_loss: 4.6163 - val_accuracy: 0.4513\n",
            "Epoch 46/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0922 - accuracy: 0.9709 - val_loss: 4.5506 - val_accuracy: 0.4463\n",
            "Epoch 47/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.1117 - accuracy: 0.9624 - val_loss: 4.1965 - val_accuracy: 0.4473\n",
            "Epoch 48/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.1159 - accuracy: 0.9614 - val_loss: 4.4414 - val_accuracy: 0.4530\n",
            "Epoch 49/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0864 - accuracy: 0.9722 - val_loss: 4.4008 - val_accuracy: 0.4610\n",
            "Epoch 50/50\n",
            "44000/44000 [==============================] - 3s 59us/sample - loss: 0.0752 - accuracy: 0.9751 - val_loss: 4.3482 - val_accuracy: 0.4495\n",
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "44000/44000 [==============================] - 3s 78us/sample - loss: 2.8932 - accuracy: 0.0879 - val_loss: 2.7302 - val_accuracy: 0.1213\n",
            "Epoch 2/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.6739 - accuracy: 0.1512 - val_loss: 2.6078 - val_accuracy: 0.1728\n",
            "Epoch 3/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 2.5387 - accuracy: 0.2005 - val_loss: 2.4271 - val_accuracy: 0.2300\n",
            "Epoch 4/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.3990 - accuracy: 0.2439 - val_loss: 2.2914 - val_accuracy: 0.2808\n",
            "Epoch 5/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 2.2639 - accuracy: 0.2867 - val_loss: 2.1667 - val_accuracy: 0.3227\n",
            "Epoch 6/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 2.1461 - accuracy: 0.3254 - val_loss: 2.0939 - val_accuracy: 0.3452\n",
            "Epoch 7/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 2.0494 - accuracy: 0.3557 - val_loss: 2.0333 - val_accuracy: 0.3582\n",
            "Epoch 8/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 1.9441 - accuracy: 0.3846 - val_loss: 1.9255 - val_accuracy: 0.3917\n",
            "Epoch 9/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 1.8454 - accuracy: 0.4139 - val_loss: 1.8797 - val_accuracy: 0.4070\n",
            "Epoch 10/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 1.7650 - accuracy: 0.4406 - val_loss: 1.8361 - val_accuracy: 0.4130\n",
            "Epoch 11/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 1.6945 - accuracy: 0.4601 - val_loss: 1.8141 - val_accuracy: 0.4330\n",
            "Epoch 12/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 1.6234 - accuracy: 0.4825 - val_loss: 1.7861 - val_accuracy: 0.4380\n",
            "Epoch 13/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 1.5326 - accuracy: 0.5085 - val_loss: 1.7364 - val_accuracy: 0.4645\n",
            "Epoch 14/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 1.4514 - accuracy: 0.5342 - val_loss: 1.6722 - val_accuracy: 0.4855\n",
            "Epoch 15/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 1.3323 - accuracy: 0.5714 - val_loss: 1.6983 - val_accuracy: 0.4835\n",
            "Epoch 16/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 1.2611 - accuracy: 0.5922 - val_loss: 1.6980 - val_accuracy: 0.4942\n",
            "Epoch 17/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 1.1851 - accuracy: 0.6175 - val_loss: 1.7506 - val_accuracy: 0.4827\n",
            "Epoch 18/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 1.0971 - accuracy: 0.6433 - val_loss: 1.7326 - val_accuracy: 0.4948\n",
            "Epoch 19/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.9831 - accuracy: 0.6780 - val_loss: 1.7975 - val_accuracy: 0.4810\n",
            "Epoch 20/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.8986 - accuracy: 0.7041 - val_loss: 1.8294 - val_accuracy: 0.4943\n",
            "Epoch 21/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.8143 - accuracy: 0.7284 - val_loss: 1.8870 - val_accuracy: 0.4908\n",
            "Epoch 22/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.7457 - accuracy: 0.7510 - val_loss: 2.0305 - val_accuracy: 0.4897\n",
            "Epoch 23/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.6685 - accuracy: 0.7764 - val_loss: 2.0901 - val_accuracy: 0.4982\n",
            "Epoch 24/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.5844 - accuracy: 0.8042 - val_loss: 2.2494 - val_accuracy: 0.4907\n",
            "Epoch 25/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.4921 - accuracy: 0.8329 - val_loss: 2.4692 - val_accuracy: 0.4915\n",
            "Epoch 26/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.4692 - accuracy: 0.8431 - val_loss: 2.3848 - val_accuracy: 0.4913\n",
            "Epoch 27/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.3986 - accuracy: 0.8648 - val_loss: 2.6357 - val_accuracy: 0.4968\n",
            "Epoch 28/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.3712 - accuracy: 0.8731 - val_loss: 2.8029 - val_accuracy: 0.4778\n",
            "Epoch 29/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.3383 - accuracy: 0.8839 - val_loss: 2.9290 - val_accuracy: 0.4835\n",
            "Epoch 30/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.3122 - accuracy: 0.8932 - val_loss: 2.7672 - val_accuracy: 0.4872\n",
            "Epoch 31/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.2488 - accuracy: 0.9155 - val_loss: 3.2209 - val_accuracy: 0.4957\n",
            "Epoch 32/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.1857 - accuracy: 0.9362 - val_loss: 3.6892 - val_accuracy: 0.4822\n",
            "Epoch 33/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.2207 - accuracy: 0.9237 - val_loss: 3.4658 - val_accuracy: 0.4903\n",
            "Epoch 34/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.1795 - accuracy: 0.9384 - val_loss: 3.3834 - val_accuracy: 0.4863\n",
            "Epoch 35/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.1665 - accuracy: 0.9438 - val_loss: 3.5533 - val_accuracy: 0.4810\n",
            "Epoch 36/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.1511 - accuracy: 0.9480 - val_loss: 3.7247 - val_accuracy: 0.4885\n",
            "Epoch 37/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.1442 - accuracy: 0.9506 - val_loss: 3.7850 - val_accuracy: 0.4942\n",
            "Epoch 38/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.1625 - accuracy: 0.9452 - val_loss: 3.4061 - val_accuracy: 0.4863\n",
            "Epoch 39/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.1363 - accuracy: 0.9541 - val_loss: 3.8602 - val_accuracy: 0.4938\n",
            "Epoch 40/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.0997 - accuracy: 0.9666 - val_loss: 3.9379 - val_accuracy: 0.4948\n",
            "Epoch 41/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.0888 - accuracy: 0.9699 - val_loss: 4.0429 - val_accuracy: 0.4913\n",
            "Epoch 42/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.1069 - accuracy: 0.9617 - val_loss: 3.9233 - val_accuracy: 0.4965\n",
            "Epoch 43/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.1259 - accuracy: 0.9573 - val_loss: 3.7951 - val_accuracy: 0.4795\n",
            "Epoch 44/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.1312 - accuracy: 0.9560 - val_loss: 3.8679 - val_accuracy: 0.4890\n",
            "Epoch 45/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.0998 - accuracy: 0.9666 - val_loss: 4.0268 - val_accuracy: 0.4922\n",
            "Epoch 46/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.0757 - accuracy: 0.9743 - val_loss: 4.4612 - val_accuracy: 0.4880\n",
            "Epoch 47/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.0748 - accuracy: 0.9739 - val_loss: 4.3992 - val_accuracy: 0.4895\n",
            "Epoch 48/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.0814 - accuracy: 0.9731 - val_loss: 4.1482 - val_accuracy: 0.4970\n",
            "Epoch 49/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.0764 - accuracy: 0.9744 - val_loss: 4.2077 - val_accuracy: 0.5022\n",
            "Epoch 50/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.0673 - accuracy: 0.9778 - val_loss: 4.6075 - val_accuracy: 0.4903\n",
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "44000/44000 [==============================] - 3s 79us/sample - loss: 2.9219 - accuracy: 0.0817 - val_loss: 2.7299 - val_accuracy: 0.1262\n",
            "Epoch 2/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.6681 - accuracy: 0.1498 - val_loss: 2.5655 - val_accuracy: 0.1855\n",
            "Epoch 3/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 2.5135 - accuracy: 0.2092 - val_loss: 2.4669 - val_accuracy: 0.2307\n",
            "Epoch 4/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.4002 - accuracy: 0.2454 - val_loss: 2.3342 - val_accuracy: 0.2622\n",
            "Epoch 5/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 2.3016 - accuracy: 0.2756 - val_loss: 2.2608 - val_accuracy: 0.2917\n",
            "Epoch 6/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.2405 - accuracy: 0.2980 - val_loss: 2.1788 - val_accuracy: 0.3238\n",
            "Epoch 7/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.1268 - accuracy: 0.3337 - val_loss: 2.1571 - val_accuracy: 0.3322\n",
            "Epoch 8/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 2.0216 - accuracy: 0.3604 - val_loss: 2.0125 - val_accuracy: 0.3738\n",
            "Epoch 9/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 1.9334 - accuracy: 0.3886 - val_loss: 1.9528 - val_accuracy: 0.3935\n",
            "Epoch 10/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 1.8237 - accuracy: 0.4228 - val_loss: 1.9066 - val_accuracy: 0.4017\n",
            "Epoch 11/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 1.7395 - accuracy: 0.4473 - val_loss: 1.8426 - val_accuracy: 0.4208\n",
            "Epoch 12/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 1.6423 - accuracy: 0.4764 - val_loss: 1.8113 - val_accuracy: 0.4283\n",
            "Epoch 13/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 1.5560 - accuracy: 0.5034 - val_loss: 1.7532 - val_accuracy: 0.4527\n",
            "Epoch 14/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 1.4662 - accuracy: 0.5303 - val_loss: 1.7709 - val_accuracy: 0.4540\n",
            "Epoch 15/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 1.3719 - accuracy: 0.5588 - val_loss: 1.7726 - val_accuracy: 0.4587\n",
            "Epoch 16/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 1.2763 - accuracy: 0.5890 - val_loss: 1.7552 - val_accuracy: 0.4660\n",
            "Epoch 17/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 1.1443 - accuracy: 0.6287 - val_loss: 1.8051 - val_accuracy: 0.4603\n",
            "Epoch 18/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 1.0476 - accuracy: 0.6607 - val_loss: 1.8733 - val_accuracy: 0.4692\n",
            "Epoch 19/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.9629 - accuracy: 0.6842 - val_loss: 1.9548 - val_accuracy: 0.4720\n",
            "Epoch 20/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.8320 - accuracy: 0.7281 - val_loss: 2.0628 - val_accuracy: 0.4625\n",
            "Epoch 21/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.7542 - accuracy: 0.7513 - val_loss: 2.1362 - val_accuracy: 0.4675\n",
            "Epoch 22/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.6688 - accuracy: 0.7788 - val_loss: 2.1983 - val_accuracy: 0.4628\n",
            "Epoch 23/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.6126 - accuracy: 0.7964 - val_loss: 2.3922 - val_accuracy: 0.4600\n",
            "Epoch 24/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.5108 - accuracy: 0.8300 - val_loss: 2.5233 - val_accuracy: 0.4647\n",
            "Epoch 25/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.4658 - accuracy: 0.8439 - val_loss: 2.5587 - val_accuracy: 0.4597\n",
            "Epoch 26/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.4000 - accuracy: 0.8651 - val_loss: 2.7344 - val_accuracy: 0.4673\n",
            "Epoch 27/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.3462 - accuracy: 0.8840 - val_loss: 2.7673 - val_accuracy: 0.4627\n",
            "Epoch 28/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.3293 - accuracy: 0.8883 - val_loss: 3.0311 - val_accuracy: 0.4598\n",
            "Epoch 29/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.2767 - accuracy: 0.9070 - val_loss: 3.0092 - val_accuracy: 0.4508\n",
            "Epoch 30/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.2586 - accuracy: 0.9133 - val_loss: 3.0559 - val_accuracy: 0.4648\n",
            "Epoch 31/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.2328 - accuracy: 0.9211 - val_loss: 3.0866 - val_accuracy: 0.4598\n",
            "Epoch 32/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.1824 - accuracy: 0.9381 - val_loss: 3.4587 - val_accuracy: 0.4668\n",
            "Epoch 33/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.2179 - accuracy: 0.9269 - val_loss: 3.3928 - val_accuracy: 0.4587\n",
            "Epoch 34/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.1572 - accuracy: 0.9465 - val_loss: 3.4649 - val_accuracy: 0.4628\n",
            "Epoch 35/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.1374 - accuracy: 0.9541 - val_loss: 3.7068 - val_accuracy: 0.4660\n",
            "Epoch 36/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.1447 - accuracy: 0.9510 - val_loss: 3.5505 - val_accuracy: 0.4565\n",
            "Epoch 37/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.1405 - accuracy: 0.9529 - val_loss: 3.8215 - val_accuracy: 0.4608\n",
            "Epoch 38/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 0.1296 - accuracy: 0.9561 - val_loss: 3.7390 - val_accuracy: 0.4672\n",
            "Epoch 39/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 0.1329 - accuracy: 0.9560 - val_loss: 3.8711 - val_accuracy: 0.4675\n",
            "Epoch 40/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.1080 - accuracy: 0.9630 - val_loss: 3.9409 - val_accuracy: 0.4628\n",
            "Epoch 41/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.1089 - accuracy: 0.9627 - val_loss: 4.0508 - val_accuracy: 0.4648\n",
            "Epoch 42/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.1068 - accuracy: 0.9648 - val_loss: 3.8281 - val_accuracy: 0.4570\n",
            "Epoch 43/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.1204 - accuracy: 0.9596 - val_loss: 4.1902 - val_accuracy: 0.4520\n",
            "Epoch 44/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 0.0895 - accuracy: 0.9702 - val_loss: 4.0720 - val_accuracy: 0.4645\n",
            "Epoch 45/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.0778 - accuracy: 0.9737 - val_loss: 4.0834 - val_accuracy: 0.4683\n",
            "Epoch 46/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.0729 - accuracy: 0.9763 - val_loss: 4.2652 - val_accuracy: 0.4663\n",
            "Epoch 47/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.0748 - accuracy: 0.9750 - val_loss: 4.2815 - val_accuracy: 0.4685\n",
            "Epoch 48/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.0866 - accuracy: 0.9715 - val_loss: 4.0014 - val_accuracy: 0.4657\n",
            "Epoch 49/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.0806 - accuracy: 0.9732 - val_loss: 4.0690 - val_accuracy: 0.4590\n",
            "Epoch 50/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.0724 - accuracy: 0.9760 - val_loss: 4.4404 - val_accuracy: 0.4567\n",
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "44000/44000 [==============================] - 4s 81us/sample - loss: 2.9329 - accuracy: 0.0783 - val_loss: 2.7937 - val_accuracy: 0.1088\n",
            "Epoch 2/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.7012 - accuracy: 0.1341 - val_loss: 2.6031 - val_accuracy: 0.1573\n",
            "Epoch 3/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.5578 - accuracy: 0.1872 - val_loss: 2.4861 - val_accuracy: 0.2055\n",
            "Epoch 4/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.4525 - accuracy: 0.2209 - val_loss: 2.3848 - val_accuracy: 0.2485\n",
            "Epoch 5/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.3341 - accuracy: 0.2606 - val_loss: 2.2471 - val_accuracy: 0.2820\n",
            "Epoch 6/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.2267 - accuracy: 0.2919 - val_loss: 2.1890 - val_accuracy: 0.3045\n",
            "Epoch 7/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.1502 - accuracy: 0.3185 - val_loss: 2.0850 - val_accuracy: 0.3488\n",
            "Epoch 8/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.0711 - accuracy: 0.3472 - val_loss: 2.0224 - val_accuracy: 0.3633\n",
            "Epoch 9/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 1.9629 - accuracy: 0.3785 - val_loss: 2.0410 - val_accuracy: 0.3558\n",
            "Epoch 10/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 1.8729 - accuracy: 0.4043 - val_loss: 1.9282 - val_accuracy: 0.3908\n",
            "Epoch 11/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 1.7736 - accuracy: 0.4353 - val_loss: 1.8764 - val_accuracy: 0.4147\n",
            "Epoch 12/50\n",
            "44000/44000 [==============================] - 3s 65us/sample - loss: 1.6739 - accuracy: 0.4637 - val_loss: 1.8666 - val_accuracy: 0.4265\n",
            "Epoch 13/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 1.5797 - accuracy: 0.4920 - val_loss: 1.9229 - val_accuracy: 0.4140\n",
            "Epoch 14/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 1.4972 - accuracy: 0.5209 - val_loss: 1.8632 - val_accuracy: 0.4362\n",
            "Epoch 15/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 1.3742 - accuracy: 0.5562 - val_loss: 1.8461 - val_accuracy: 0.4520\n",
            "Epoch 16/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 1.2645 - accuracy: 0.5892 - val_loss: 1.8483 - val_accuracy: 0.4557\n",
            "Epoch 17/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 1.1551 - accuracy: 0.6233 - val_loss: 1.9810 - val_accuracy: 0.4382\n",
            "Epoch 18/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 1.0712 - accuracy: 0.6520 - val_loss: 1.9561 - val_accuracy: 0.4552\n",
            "Epoch 19/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 1.0071 - accuracy: 0.6708 - val_loss: 2.0009 - val_accuracy: 0.4527\n",
            "Epoch 20/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.8702 - accuracy: 0.7148 - val_loss: 2.1147 - val_accuracy: 0.4455\n",
            "Epoch 21/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.7929 - accuracy: 0.7384 - val_loss: 2.2013 - val_accuracy: 0.4535\n",
            "Epoch 22/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.6546 - accuracy: 0.7822 - val_loss: 2.5013 - val_accuracy: 0.4343\n",
            "Epoch 23/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 0.6289 - accuracy: 0.7900 - val_loss: 2.5517 - val_accuracy: 0.4447\n",
            "Epoch 24/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.5301 - accuracy: 0.8233 - val_loss: 2.6048 - val_accuracy: 0.4423\n",
            "Epoch 25/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.4686 - accuracy: 0.8444 - val_loss: 2.7637 - val_accuracy: 0.4523\n",
            "Epoch 26/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.4370 - accuracy: 0.8518 - val_loss: 2.8466 - val_accuracy: 0.4480\n",
            "Epoch 27/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.3672 - accuracy: 0.8758 - val_loss: 2.9683 - val_accuracy: 0.4400\n",
            "Epoch 28/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.3253 - accuracy: 0.8892 - val_loss: 3.1762 - val_accuracy: 0.4453\n",
            "Epoch 29/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.2803 - accuracy: 0.9054 - val_loss: 3.3264 - val_accuracy: 0.4433\n",
            "Epoch 30/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.2687 - accuracy: 0.9104 - val_loss: 3.2642 - val_accuracy: 0.4425\n",
            "Epoch 31/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 0.2324 - accuracy: 0.9227 - val_loss: 3.4366 - val_accuracy: 0.4480\n",
            "Epoch 32/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 0.2229 - accuracy: 0.9254 - val_loss: 3.5361 - val_accuracy: 0.4458\n",
            "Epoch 33/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.2069 - accuracy: 0.9295 - val_loss: 3.7511 - val_accuracy: 0.4578\n",
            "Epoch 34/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.1786 - accuracy: 0.9397 - val_loss: 3.6766 - val_accuracy: 0.4488\n",
            "Epoch 35/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.1819 - accuracy: 0.9387 - val_loss: 3.8358 - val_accuracy: 0.4355\n",
            "Epoch 36/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 0.1676 - accuracy: 0.9425 - val_loss: 3.8984 - val_accuracy: 0.4515\n",
            "Epoch 37/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.1651 - accuracy: 0.9442 - val_loss: 3.7801 - val_accuracy: 0.4440\n",
            "Epoch 38/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.1463 - accuracy: 0.9505 - val_loss: 3.8728 - val_accuracy: 0.4472\n",
            "Epoch 39/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.1175 - accuracy: 0.9611 - val_loss: 4.3183 - val_accuracy: 0.4343\n",
            "Epoch 40/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.1228 - accuracy: 0.9586 - val_loss: 3.9408 - val_accuracy: 0.4425\n",
            "Epoch 41/50\n",
            "44000/44000 [==============================] - 3s 62us/sample - loss: 0.1140 - accuracy: 0.9621 - val_loss: 4.2679 - val_accuracy: 0.4440\n",
            "Epoch 42/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.1202 - accuracy: 0.9590 - val_loss: 4.0469 - val_accuracy: 0.4475\n",
            "Epoch 43/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 0.1068 - accuracy: 0.9641 - val_loss: 4.0176 - val_accuracy: 0.4425\n",
            "Epoch 44/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.1001 - accuracy: 0.9673 - val_loss: 4.2653 - val_accuracy: 0.4455\n",
            "Epoch 45/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.0961 - accuracy: 0.9677 - val_loss: 4.4241 - val_accuracy: 0.4377\n",
            "Epoch 46/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.1251 - accuracy: 0.9585 - val_loss: 4.2277 - val_accuracy: 0.4452\n",
            "Epoch 47/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.0842 - accuracy: 0.9721 - val_loss: 4.5493 - val_accuracy: 0.4412\n",
            "Epoch 48/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.1040 - accuracy: 0.9652 - val_loss: 4.1600 - val_accuracy: 0.4425\n",
            "Epoch 49/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.0831 - accuracy: 0.9713 - val_loss: 4.3442 - val_accuracy: 0.4415\n",
            "Epoch 50/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.0814 - accuracy: 0.9726 - val_loss: 4.3898 - val_accuracy: 0.4515\n",
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "44000/44000 [==============================] - 4s 83us/sample - loss: 2.9958 - accuracy: 0.0550 - val_loss: 2.9964 - val_accuracy: 0.0462\n",
            "Epoch 2/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.9957 - accuracy: 0.0510 - val_loss: 2.9974 - val_accuracy: 0.0528\n",
            "Epoch 3/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 3.0019 - accuracy: 0.0524 - val_loss: 2.9966 - val_accuracy: 0.0472\n",
            "Epoch 4/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.9959 - accuracy: 0.0487 - val_loss: 2.9963 - val_accuracy: 0.0492\n",
            "Epoch 5/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.9958 - accuracy: 0.0496 - val_loss: 2.9962 - val_accuracy: 0.0472\n",
            "Epoch 6/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.9958 - accuracy: 0.0497 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 7/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.9957 - accuracy: 0.0507 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 8/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.9958 - accuracy: 0.0502 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 9/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.9957 - accuracy: 0.0497 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 10/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.9958 - accuracy: 0.0484 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 11/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.9957 - accuracy: 0.0502 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 12/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 13/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 3.0127 - accuracy: 0.0526 - val_loss: 2.9967 - val_accuracy: 0.0462\n",
            "Epoch 14/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 3.0004 - accuracy: 0.0522 - val_loss: 2.9984 - val_accuracy: 0.0478\n",
            "Epoch 15/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.9959 - accuracy: 0.0504 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 16/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.9958 - accuracy: 0.0489 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 17/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.9958 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 18/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 19/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.9957 - accuracy: 0.0491 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 20/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 21/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.9957 - accuracy: 0.0491 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 22/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.9958 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 23/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 24/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 25/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 26/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.9957 - accuracy: 0.0496 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 27/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.9957 - accuracy: 0.0502 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 28/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 29/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.9957 - accuracy: 0.0503 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 30/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 31/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 32/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 33/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 34/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.9957 - accuracy: 0.0487 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 35/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 36/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 37/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.9957 - accuracy: 0.0488 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 38/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.9957 - accuracy: 0.0506 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 39/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.9958 - accuracy: 0.0487 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 40/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 3.0232 - accuracy: 0.0503 - val_loss: 2.9968 - val_accuracy: 0.0440\n",
            "Epoch 41/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.9957 - accuracy: 0.0496 - val_loss: 2.9957 - val_accuracy: 0.0437\n",
            "Epoch 42/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.9961 - accuracy: 0.0505 - val_loss: 2.9970 - val_accuracy: 0.0440\n",
            "Epoch 43/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.9958 - accuracy: 0.0487 - val_loss: 2.9966 - val_accuracy: 0.0448\n",
            "Epoch 44/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.9957 - accuracy: 0.0491 - val_loss: 2.9966 - val_accuracy: 0.0440\n",
            "Epoch 45/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 46/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.9957 - accuracy: 0.0487 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 47/50\n",
            "44000/44000 [==============================] - 3s 65us/sample - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 48/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.9957 - accuracy: 0.0496 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 49/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 50/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.9957 - accuracy: 0.0496 - val_loss: 2.9965 - val_accuracy: 0.0448\n",
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "44000/44000 [==============================] - 4s 83us/sample - loss: 2.9970 - accuracy: 0.0508 - val_loss: 2.9951 - val_accuracy: 0.0457\n",
            "Epoch 2/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.9381 - accuracy: 0.0730 - val_loss: 2.8109 - val_accuracy: 0.1030\n",
            "Epoch 3/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.7758 - accuracy: 0.1145 - val_loss: 2.8386 - val_accuracy: 0.1010\n",
            "Epoch 4/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.7122 - accuracy: 0.1289 - val_loss: 2.6004 - val_accuracy: 0.1570\n",
            "Epoch 5/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.5851 - accuracy: 0.1701 - val_loss: 2.4962 - val_accuracy: 0.2018\n",
            "Epoch 6/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.4961 - accuracy: 0.2035 - val_loss: 2.4283 - val_accuracy: 0.2175\n",
            "Epoch 7/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.4172 - accuracy: 0.2304 - val_loss: 2.3766 - val_accuracy: 0.2403\n",
            "Epoch 8/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 2.3856 - accuracy: 0.2408 - val_loss: 2.3283 - val_accuracy: 0.2562\n",
            "Epoch 9/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.2954 - accuracy: 0.2686 - val_loss: 2.2297 - val_accuracy: 0.2840\n",
            "Epoch 10/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.2127 - accuracy: 0.2917 - val_loss: 2.1478 - val_accuracy: 0.3137\n",
            "Epoch 11/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.1610 - accuracy: 0.3086 - val_loss: 2.2179 - val_accuracy: 0.2970\n",
            "Epoch 12/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 2.0748 - accuracy: 0.3369 - val_loss: 2.0764 - val_accuracy: 0.3347\n",
            "Epoch 13/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 1.9819 - accuracy: 0.3610 - val_loss: 1.9911 - val_accuracy: 0.3692\n",
            "Epoch 14/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 1.9198 - accuracy: 0.3860 - val_loss: 2.0603 - val_accuracy: 0.3585\n",
            "Epoch 15/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 1.8587 - accuracy: 0.4023 - val_loss: 1.9939 - val_accuracy: 0.3735\n",
            "Epoch 16/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 1.7611 - accuracy: 0.4321 - val_loss: 1.9616 - val_accuracy: 0.3963\n",
            "Epoch 17/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 1.6923 - accuracy: 0.4540 - val_loss: 1.8662 - val_accuracy: 0.4148\n",
            "Epoch 18/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 1.6120 - accuracy: 0.4783 - val_loss: 1.8815 - val_accuracy: 0.4093\n",
            "Epoch 19/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 1.5296 - accuracy: 0.5027 - val_loss: 1.8919 - val_accuracy: 0.4297\n",
            "Epoch 20/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 1.4558 - accuracy: 0.5296 - val_loss: 1.8749 - val_accuracy: 0.4278\n",
            "Epoch 21/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 1.3944 - accuracy: 0.5480 - val_loss: 1.8829 - val_accuracy: 0.4340\n",
            "Epoch 22/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 1.3261 - accuracy: 0.5705 - val_loss: 1.8970 - val_accuracy: 0.4377\n",
            "Epoch 23/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 1.2292 - accuracy: 0.5990 - val_loss: 1.8884 - val_accuracy: 0.4530\n",
            "Epoch 24/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 1.1562 - accuracy: 0.6187 - val_loss: 1.9687 - val_accuracy: 0.4448\n",
            "Epoch 25/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 1.0819 - accuracy: 0.6471 - val_loss: 2.0220 - val_accuracy: 0.4435\n",
            "Epoch 26/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 1.0117 - accuracy: 0.6674 - val_loss: 1.9768 - val_accuracy: 0.4532\n",
            "Epoch 27/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 0.9170 - accuracy: 0.6995 - val_loss: 2.1641 - val_accuracy: 0.4517\n",
            "Epoch 28/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.8881 - accuracy: 0.7069 - val_loss: 2.2059 - val_accuracy: 0.4542\n",
            "Epoch 29/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 0.8081 - accuracy: 0.7356 - val_loss: 2.2880 - val_accuracy: 0.4477\n",
            "Epoch 30/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 0.7476 - accuracy: 0.7510 - val_loss: 2.3558 - val_accuracy: 0.4425\n",
            "Epoch 31/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 0.7262 - accuracy: 0.7607 - val_loss: 2.4300 - val_accuracy: 0.4402\n",
            "Epoch 32/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 0.6143 - accuracy: 0.7961 - val_loss: 2.6347 - val_accuracy: 0.4480\n",
            "Epoch 33/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.6296 - accuracy: 0.7906 - val_loss: 2.5038 - val_accuracy: 0.4450\n",
            "Epoch 34/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 0.5794 - accuracy: 0.8077 - val_loss: 2.6147 - val_accuracy: 0.4475\n",
            "Epoch 35/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 0.4955 - accuracy: 0.8350 - val_loss: 2.6729 - val_accuracy: 0.4532\n",
            "Epoch 36/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 0.4603 - accuracy: 0.8499 - val_loss: 2.8061 - val_accuracy: 0.4515\n",
            "Epoch 37/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 0.4193 - accuracy: 0.8613 - val_loss: 2.8847 - val_accuracy: 0.4450\n",
            "Epoch 38/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.4057 - accuracy: 0.8660 - val_loss: 3.0016 - val_accuracy: 0.4495\n",
            "Epoch 39/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 0.3739 - accuracy: 0.8780 - val_loss: 3.0756 - val_accuracy: 0.4507\n",
            "Epoch 40/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 0.3732 - accuracy: 0.8773 - val_loss: 2.8348 - val_accuracy: 0.4503\n",
            "Epoch 41/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 0.3400 - accuracy: 0.8875 - val_loss: 3.0553 - val_accuracy: 0.4475\n",
            "Epoch 42/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 0.2953 - accuracy: 0.9029 - val_loss: 3.3317 - val_accuracy: 0.4433\n",
            "Epoch 43/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 0.2850 - accuracy: 0.9072 - val_loss: 3.1684 - val_accuracy: 0.4512\n",
            "Epoch 44/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 0.2765 - accuracy: 0.9089 - val_loss: 3.3606 - val_accuracy: 0.4467\n",
            "Epoch 45/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 0.2503 - accuracy: 0.9177 - val_loss: 3.4294 - val_accuracy: 0.4590\n",
            "Epoch 46/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.2287 - accuracy: 0.9250 - val_loss: 3.7054 - val_accuracy: 0.4497\n",
            "Epoch 47/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 0.2104 - accuracy: 0.9313 - val_loss: 3.8016 - val_accuracy: 0.4558\n",
            "Epoch 48/50\n",
            "44000/44000 [==============================] - 3s 64us/sample - loss: 0.2046 - accuracy: 0.9331 - val_loss: 3.6366 - val_accuracy: 0.4447\n",
            "Epoch 49/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.1939 - accuracy: 0.9370 - val_loss: 3.6764 - val_accuracy: 0.4477\n",
            "Epoch 50/50\n",
            "44000/44000 [==============================] - 3s 63us/sample - loss: 0.1806 - accuracy: 0.9423 - val_loss: 3.7722 - val_accuracy: 0.4508\n",
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "44000/44000 [==============================] - 4s 83us/sample - loss: 2.9963 - accuracy: 0.0484 - val_loss: 2.9963 - val_accuracy: 0.0448\n",
            "Epoch 2/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9958 - accuracy: 0.0492 - val_loss: 2.9962 - val_accuracy: 0.0448\n",
            "Epoch 3/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 3.0102 - accuracy: 0.0490 - val_loss: 2.9960 - val_accuracy: 0.0462\n",
            "Epoch 4/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9954 - accuracy: 0.0503 - val_loss: 2.9964 - val_accuracy: 0.0492\n",
            "Epoch 5/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9959 - accuracy: 0.0486 - val_loss: 2.9963 - val_accuracy: 0.0462\n",
            "Epoch 6/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9958 - accuracy: 0.0483 - val_loss: 2.9963 - val_accuracy: 0.0492\n",
            "Epoch 7/50\n",
            "44000/44000 [==============================] - 3s 67us/sample - loss: 2.9958 - accuracy: 0.0489 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 8/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9958 - accuracy: 0.0496 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 9/50\n",
            "44000/44000 [==============================] - 3s 67us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 10/50\n",
            "44000/44000 [==============================] - 3s 67us/sample - loss: 2.9958 - accuracy: 0.0497 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 11/50\n",
            "44000/44000 [==============================] - 3s 65us/sample - loss: 2.9958 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 12/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9958 - accuracy: 0.0497 - val_loss: 2.9963 - val_accuracy: 0.0462\n",
            "Epoch 13/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9958 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 14/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9958 - accuracy: 0.0497 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 15/50\n",
            "44000/44000 [==============================] - 3s 67us/sample - loss: 2.9958 - accuracy: 0.0504 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 16/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9958 - accuracy: 0.0508 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 17/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9957 - accuracy: 0.0484 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 18/50\n",
            "44000/44000 [==============================] - 3s 67us/sample - loss: 2.9958 - accuracy: 0.0500 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 19/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9957 - accuracy: 0.0501 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 20/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 21/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9958 - accuracy: 0.0499 - val_loss: 2.9965 - val_accuracy: 0.0448\n",
            "Epoch 22/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 23/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9958 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 24/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 25/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 26/50\n",
            "44000/44000 [==============================] - 3s 67us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 27/50\n",
            "44000/44000 [==============================] - 3s 67us/sample - loss: 2.9957 - accuracy: 0.0491 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 28/50\n",
            "44000/44000 [==============================] - 3s 67us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 29/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9958 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 30/50\n",
            "44000/44000 [==============================] - 3s 67us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 31/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0457\n",
            "Epoch 32/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 33/50\n",
            "44000/44000 [==============================] - 3s 67us/sample - loss: 2.9957 - accuracy: 0.0494 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 34/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 35/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 36/50\n",
            "44000/44000 [==============================] - 3s 67us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 37/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 38/50\n",
            "44000/44000 [==============================] - 3s 67us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 39/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 40/50\n",
            "44000/44000 [==============================] - 3s 67us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 41/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 42/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9957 - accuracy: 0.0496 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 43/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9957 - accuracy: 0.0492 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 44/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9957 - accuracy: 0.0493 - val_loss: 2.9964 - val_accuracy: 0.0462\n",
            "Epoch 45/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9957 - accuracy: 0.0507 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 46/50\n",
            "44000/44000 [==============================] - 3s 67us/sample - loss: 2.9957 - accuracy: 0.0493 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 47/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9958 - accuracy: 0.0508 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 48/50\n",
            "44000/44000 [==============================] - 3s 67us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 49/50\n",
            "44000/44000 [==============================] - 3s 66us/sample - loss: 2.9957 - accuracy: 0.0496 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 50/50\n",
            "44000/44000 [==============================] - 3s 67us/sample - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "44000/44000 [==============================] - 4s 98us/sample - loss: 2.9976 - accuracy: 0.0508 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 2/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0491 - val_loss: 2.9962 - val_accuracy: 0.0457\n",
            "Epoch 3/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0488 - val_loss: 2.9963 - val_accuracy: 0.0457\n",
            "Epoch 4/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0495 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 5/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0492 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 6/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0491 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 7/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0507 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 8/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9958 - accuracy: 0.0493 - val_loss: 2.9964 - val_accuracy: 0.0457\n",
            "Epoch 9/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0490 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 10/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0502 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 11/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0484 - val_loss: 2.9963 - val_accuracy: 0.0448\n",
            "Epoch 12/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9958 - accuracy: 0.0485 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 13/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 14/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0496 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 15/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0505 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 16/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0500 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 17/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0501 - val_loss: 2.9963 - val_accuracy: 0.0448\n",
            "Epoch 18/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9958 - accuracy: 0.0505 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 19/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 20/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9963 - val_accuracy: 0.0448\n",
            "Epoch 21/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0507 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 22/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 23/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0491 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 24/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 25/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 26/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 27/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 28/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0506 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 29/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 30/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 31/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 32/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 33/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0494 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 34/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0491 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 35/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 36/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 37/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 38/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0510 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 39/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0497 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 40/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0492 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 41/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 42/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 43/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 44/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 45/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 46/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0489 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 47/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 48/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0494 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 49/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0492 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 50/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "44000/44000 [==============================] - 4s 89us/sample - loss: 2.9962 - accuracy: 0.0478 - val_loss: 2.9963 - val_accuracy: 0.0492\n",
            "Epoch 2/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9962 - accuracy: 0.0501 - val_loss: 2.9967 - val_accuracy: 0.0462\n",
            "Epoch 3/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0489 - val_loss: 2.9962 - val_accuracy: 0.0457\n",
            "Epoch 4/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0487 - val_loss: 2.9961 - val_accuracy: 0.0448\n",
            "Epoch 5/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 6/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9958 - accuracy: 0.0499 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 7/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0501 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 8/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 9/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0487 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 10/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9958 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 11/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0486 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 12/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0491 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 13/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0487 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 14/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0485 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 15/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0488 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 16/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0486 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 17/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0496 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 18/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 19/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 20/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 21/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 22/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 23/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0505 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 24/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0487 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 25/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0493 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 26/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0502 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 27/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 28/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 29/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 30/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 31/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0497 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 32/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 33/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 34/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 35/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 36/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0492 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 37/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0505 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 38/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 39/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0496 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 40/50\n",
            "44000/44000 [==============================] - 3s 67us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 41/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 42/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0501 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 43/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 44/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0501 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 45/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0481 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 46/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0507 - val_loss: 2.9965 - val_accuracy: 0.0448\n",
            "Epoch 47/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0509 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 48/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 49/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 50/50\n",
            "44000/44000 [==============================] - 3s 67us/sample - loss: 2.9957 - accuracy: 0.0492 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "44000/44000 [==============================] - 4s 88us/sample - loss: 2.9969 - accuracy: 0.0493 - val_loss: 2.9961 - val_accuracy: 0.0492\n",
            "Epoch 2/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9958 - accuracy: 0.0499 - val_loss: 2.9964 - val_accuracy: 0.0457\n",
            "Epoch 3/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0494 - val_loss: 2.9962 - val_accuracy: 0.0470\n",
            "Epoch 4/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9958 - accuracy: 0.0495 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 5/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0488 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 6/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0482 - val_loss: 2.9963 - val_accuracy: 0.0462\n",
            "Epoch 7/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0497 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 8/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0485 - val_loss: 2.9964 - val_accuracy: 0.0462\n",
            "Epoch 9/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0512 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 10/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0489 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 11/50\n",
            "44000/44000 [==============================] - 3s 67us/sample - loss: 2.9958 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 12/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 13/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 14/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 15/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0503 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 16/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0490 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 17/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0502 - val_loss: 2.9963 - val_accuracy: 0.0448\n",
            "Epoch 18/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 19/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0493 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 20/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0480 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 21/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 22/50\n",
            "44000/44000 [==============================] - 3s 67us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 23/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 24/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0489 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 25/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 26/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0504 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 27/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 28/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 29/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 30/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 31/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 32/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0505 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 33/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 34/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0506 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 35/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 36/50\n",
            "44000/44000 [==============================] - 3s 67us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 37/50\n",
            "44000/44000 [==============================] - 3s 67us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 38/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 39/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 40/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 41/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 42/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0502 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 43/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0505 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 44/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 45/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 46/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 47/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 48/50\n",
            "44000/44000 [==============================] - 3s 67us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 49/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 50/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0489 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "44000/44000 [==============================] - 4s 89us/sample - loss: 2.9962 - accuracy: 0.0496 - val_loss: 2.9961 - val_accuracy: 0.0462\n",
            "Epoch 2/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9959 - accuracy: 0.0504 - val_loss: 2.9962 - val_accuracy: 0.0440\n",
            "Epoch 3/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0487 - val_loss: 2.9962 - val_accuracy: 0.0440\n",
            "Epoch 4/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0506 - val_loss: 2.9962 - val_accuracy: 0.0457\n",
            "Epoch 5/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9958 - accuracy: 0.0502 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 6/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9958 - accuracy: 0.0504 - val_loss: 2.9964 - val_accuracy: 0.0457\n",
            "Epoch 7/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9958 - accuracy: 0.0501 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 8/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9958 - accuracy: 0.0492 - val_loss: 2.9963 - val_accuracy: 0.0448\n",
            "Epoch 9/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0506 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 10/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9958 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 11/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0504 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 12/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0488 - val_loss: 2.9963 - val_accuracy: 0.0448\n",
            "Epoch 13/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9958 - accuracy: 0.0506 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 14/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 15/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0502 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 16/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9958 - accuracy: 0.0498 - val_loss: 2.9963 - val_accuracy: 0.0448\n",
            "Epoch 17/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0507 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 18/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 19/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0494 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 20/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 21/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0501 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 22/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 23/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 24/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 25/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 26/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0494 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 27/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0497 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 28/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0507 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 29/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 30/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0488 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 31/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0511 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 32/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0493 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 33/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0490 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 34/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 35/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 36/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 37/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 38/50\n",
            "44000/44000 [==============================] - 3s 67us/sample - loss: 2.9957 - accuracy: 0.0492 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 39/50\n",
            "44000/44000 [==============================] - 3s 67us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 40/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 41/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 42/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0493 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 43/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 44/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 45/50\n",
            "44000/44000 [==============================] - 3s 69us/sample - loss: 2.9957 - accuracy: 0.0486 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 46/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 47/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0494 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 48/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 49/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9958 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 50/50\n",
            "44000/44000 [==============================] - 3s 68us/sample - loss: 2.9957 - accuracy: 0.0507 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "44000/44000 [==============================] - 4s 90us/sample - loss: 2.9956 - accuracy: 0.0491 - val_loss: 2.9961 - val_accuracy: 0.0440\n",
            "Epoch 2/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9958 - accuracy: 0.0501 - val_loss: 2.9962 - val_accuracy: 0.0448\n",
            "Epoch 3/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9958 - accuracy: 0.0494 - val_loss: 2.9963 - val_accuracy: 0.0472\n",
            "Epoch 4/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9958 - accuracy: 0.0493 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 5/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9958 - accuracy: 0.0479 - val_loss: 2.9964 - val_accuracy: 0.0472\n",
            "Epoch 6/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9958 - accuracy: 0.0489 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 7/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9958 - accuracy: 0.0487 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 8/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0481 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 9/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9958 - accuracy: 0.0508 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 10/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 11/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9958 - accuracy: 0.0472 - val_loss: 2.9963 - val_accuracy: 0.0457\n",
            "Epoch 12/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9958 - accuracy: 0.0500 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 13/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9958 - accuracy: 0.0487 - val_loss: 2.9963 - val_accuracy: 0.0457\n",
            "Epoch 14/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 15/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9958 - accuracy: 0.0499 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 16/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 17/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 18/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0492 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 19/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 20/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 21/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 22/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 23/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 24/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 25/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 26/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 27/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 28/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 29/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0501 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 30/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 31/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0484 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 32/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 33/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 34/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 35/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 36/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 37/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 38/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0493 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 39/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0503 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 40/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 41/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 42/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 43/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 44/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0494 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 45/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0487 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 46/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0477 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 47/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 48/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 49/50\n",
            "44000/44000 [==============================] - 3s 70us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 50/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "44000/44000 [==============================] - 4s 91us/sample - loss: 2.9940 - accuracy: 0.0532 - val_loss: 2.9950 - val_accuracy: 0.0540\n",
            "Epoch 2/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9963 - val_accuracy: 0.0462\n",
            "Epoch 3/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9958 - accuracy: 0.0488 - val_loss: 2.9962 - val_accuracy: 0.0440\n",
            "Epoch 4/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9958 - accuracy: 0.0508 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 5/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9958 - accuracy: 0.0496 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 6/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9958 - accuracy: 0.0499 - val_loss: 2.9963 - val_accuracy: 0.0462\n",
            "Epoch 7/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9958 - accuracy: 0.0504 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 8/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9958 - accuracy: 0.0492 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 9/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9958 - accuracy: 0.0492 - val_loss: 2.9965 - val_accuracy: 0.0448\n",
            "Epoch 10/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9958 - accuracy: 0.0491 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 11/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9958 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 12/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9958 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 13/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0497 - val_loss: 2.9963 - val_accuracy: 0.0448\n",
            "Epoch 14/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9958 - accuracy: 0.0500 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 15/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0506 - val_loss: 2.9963 - val_accuracy: 0.0448\n",
            "Epoch 16/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0507 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 17/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0505 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 18/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 19/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0504 - val_loss: 2.9963 - val_accuracy: 0.0448\n",
            "Epoch 20/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 21/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0502 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 22/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0492 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 23/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 24/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9958 - accuracy: 0.0490 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 25/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0492 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 26/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 27/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 28/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0492 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 29/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 30/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0503 - val_loss: 2.9965 - val_accuracy: 0.0448\n",
            "Epoch 31/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 32/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0502 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 33/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0496 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 34/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0502 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 35/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0503 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 36/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0497 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 37/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0501 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 38/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 39/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 40/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0505 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 41/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 42/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 43/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 44/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 45/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 46/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0501 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 47/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0505 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 48/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0489 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 49/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0490 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 50/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "44000/44000 [==============================] - 5s 102us/sample - loss: 3.0057 - accuracy: 0.0483 - val_loss: 2.9962 - val_accuracy: 0.0440\n",
            "Epoch 2/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9958 - accuracy: 0.0485 - val_loss: 2.9961 - val_accuracy: 0.0462\n",
            "Epoch 3/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9958 - accuracy: 0.0480 - val_loss: 2.9961 - val_accuracy: 0.0457\n",
            "Epoch 4/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9958 - accuracy: 0.0497 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 5/50\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 2.9958 - accuracy: 0.0499 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 6/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9958 - accuracy: 0.0498 - val_loss: 2.9963 - val_accuracy: 0.0448\n",
            "Epoch 7/50\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 2.9958 - accuracy: 0.0493 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 8/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9958 - accuracy: 0.0497 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 9/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9958 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 10/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 11/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0486 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 12/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 13/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9958 - accuracy: 0.0490 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 14/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0490 - val_loss: 2.9963 - val_accuracy: 0.0462\n",
            "Epoch 15/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9958 - accuracy: 0.0507 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 16/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9958 - accuracy: 0.0487 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 17/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0496 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 18/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0490 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 19/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0496 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 20/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0486 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 21/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 22/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0491 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 23/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 24/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 25/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0504 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 26/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0504 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 27/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0503 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 28/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 29/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 30/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 31/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0496 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 32/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0493 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 33/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 34/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0483 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 35/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0504 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 36/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 37/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 38/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0488 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 39/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0509 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 40/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0488 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 41/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 42/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0496 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 43/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 44/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0503 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 45/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 46/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0493 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 47/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0513 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 48/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 49/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 50/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "44000/44000 [==============================] - 4s 93us/sample - loss: 2.9991 - accuracy: 0.0495 - val_loss: 2.9961 - val_accuracy: 0.0462\n",
            "Epoch 2/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9958 - accuracy: 0.0493 - val_loss: 2.9961 - val_accuracy: 0.0457\n",
            "Epoch 3/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9958 - accuracy: 0.0490 - val_loss: 2.9960 - val_accuracy: 0.0440\n",
            "Epoch 4/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9958 - accuracy: 0.0508 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 5/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9958 - accuracy: 0.0506 - val_loss: 2.9962 - val_accuracy: 0.0462\n",
            "Epoch 6/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9958 - accuracy: 0.0488 - val_loss: 2.9963 - val_accuracy: 0.0470\n",
            "Epoch 7/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9958 - accuracy: 0.0483 - val_loss: 2.9962 - val_accuracy: 0.0440\n",
            "Epoch 8/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9958 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 9/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9958 - accuracy: 0.0497 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 10/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9958 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 11/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0491 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 12/50\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 13/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9963 - val_accuracy: 0.0448\n",
            "Epoch 14/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 15/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 16/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 17/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 18/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 19/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0507 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 20/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0492 - val_loss: 2.9964 - val_accuracy: 0.0457\n",
            "Epoch 21/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0506 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 22/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0496 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 23/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 24/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0497 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 25/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0510 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 26/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0504 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 27/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 28/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 29/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0503 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 30/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 31/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0501 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 32/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 33/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 34/50\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 35/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 36/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0504 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 37/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 38/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 39/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 40/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0501 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 41/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0506 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 42/50\n",
            "44000/44000 [==============================] - 3s 71us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 43/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0486 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 44/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0501 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 45/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0496 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 46/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0507 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 47/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 48/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0489 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 49/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0485 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 50/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0493 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "44000/44000 [==============================] - 4s 97us/sample - loss: 3.0055 - accuracy: 0.0519 - val_loss: 2.9962 - val_accuracy: 0.0475\n",
            "Epoch 2/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9958 - accuracy: 0.0491 - val_loss: 2.9963 - val_accuracy: 0.0475\n",
            "Epoch 3/50\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 2.9958 - accuracy: 0.0503 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 4/50\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 2.9958 - accuracy: 0.0496 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 5/50\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 2.9958 - accuracy: 0.0477 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 6/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9958 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 7/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0493 - val_loss: 2.9964 - val_accuracy: 0.0457\n",
            "Epoch 8/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9958 - accuracy: 0.0498 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 9/50\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 10/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0475 - val_loss: 2.9964 - val_accuracy: 0.0457\n",
            "Epoch 11/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9958 - accuracy: 0.0504 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 12/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0497 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 13/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0491 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 14/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 15/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 16/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0488 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 17/50\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 2.9957 - accuracy: 0.0497 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 18/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0493 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 19/50\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 20/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 21/50\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 22/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0493 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 23/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0497 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 24/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9965 - val_accuracy: 0.0448\n",
            "Epoch 25/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0506 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 26/50\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 27/50\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 2.9957 - accuracy: 0.0490 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 28/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 29/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0490 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 30/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 31/50\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 32/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0497 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 33/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 34/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 35/50\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 36/50\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 2.9957 - accuracy: 0.0493 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 37/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0504 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 38/50\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 39/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0501 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 40/50\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 2.9957 - accuracy: 0.0507 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 41/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0503 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 42/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 43/50\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 44/50\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 45/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 46/50\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 2.9957 - accuracy: 0.0493 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 47/50\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 2.9957 - accuracy: 0.0488 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 48/50\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 49/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 50/50\n",
            "44000/44000 [==============================] - 3s 72us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "44000/44000 [==============================] - 4s 95us/sample - loss: 2.9955 - accuracy: 0.0487 - val_loss: 2.9962 - val_accuracy: 0.0472\n",
            "Epoch 2/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9958 - accuracy: 0.0492 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 3/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9958 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 4/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9958 - accuracy: 0.0509 - val_loss: 2.9962 - val_accuracy: 0.0457\n",
            "Epoch 5/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9958 - accuracy: 0.0498 - val_loss: 2.9963 - val_accuracy: 0.0448\n",
            "Epoch 6/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9958 - accuracy: 0.0507 - val_loss: 2.9963 - val_accuracy: 0.0448\n",
            "Epoch 7/50\n",
            "44000/44000 [==============================] - 3s 74us/sample - loss: 2.9958 - accuracy: 0.0490 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 8/50\n",
            "44000/44000 [==============================] - 3s 74us/sample - loss: 2.9957 - accuracy: 0.0491 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 9/50\n",
            "44000/44000 [==============================] - 3s 74us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 10/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9958 - accuracy: 0.0501 - val_loss: 2.9963 - val_accuracy: 0.0448\n",
            "Epoch 11/50\n",
            "44000/44000 [==============================] - 3s 74us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 12/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0488 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 13/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 14/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 15/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0457\n",
            "Epoch 16/50\n",
            "44000/44000 [==============================] - 3s 74us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 17/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0480 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 18/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0505 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 19/50\n",
            "44000/44000 [==============================] - 3s 74us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 20/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0494 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 21/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 22/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 23/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 24/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0494 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 25/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0497 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 26/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0502 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 27/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 28/50\n",
            "44000/44000 [==============================] - 3s 74us/sample - loss: 2.9957 - accuracy: 0.0505 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 29/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9958 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 30/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 31/50\n",
            "44000/44000 [==============================] - 3s 74us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 32/50\n",
            "44000/44000 [==============================] - 3s 74us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 33/50\n",
            "44000/44000 [==============================] - 3s 74us/sample - loss: 2.9957 - accuracy: 0.0512 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 34/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 35/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0491 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 36/50\n",
            "44000/44000 [==============================] - 3s 74us/sample - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 37/50\n",
            "44000/44000 [==============================] - 3s 74us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 38/50\n",
            "44000/44000 [==============================] - 3s 74us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 39/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0491 - val_loss: 2.9964 - val_accuracy: 0.0457\n",
            "Epoch 40/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0502 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 41/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 42/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 43/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 44/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9963 - val_accuracy: 0.0448\n",
            "Epoch 45/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0504 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 46/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0501 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 47/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 48/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 49/50\n",
            "44000/44000 [==============================] - 3s 74us/sample - loss: 2.9957 - accuracy: 0.0491 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 50/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0505 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "44000/44000 [==============================] - 4s 97us/sample - loss: 2.9958 - accuracy: 0.0504 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 2/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9959 - accuracy: 0.0488 - val_loss: 2.9962 - val_accuracy: 0.0457\n",
            "Epoch 3/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9958 - accuracy: 0.0494 - val_loss: 2.9963 - val_accuracy: 0.0470\n",
            "Epoch 4/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9958 - accuracy: 0.0499 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 5/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9958 - accuracy: 0.0497 - val_loss: 2.9963 - val_accuracy: 0.0457\n",
            "Epoch 6/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0507 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 7/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9958 - accuracy: 0.0502 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 8/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0478 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 9/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0496 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 10/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9958 - accuracy: 0.0502 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 11/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9958 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 12/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9958 - accuracy: 0.0495 - val_loss: 2.9963 - val_accuracy: 0.0448\n",
            "Epoch 13/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9958 - accuracy: 0.0501 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 14/50\n",
            "44000/44000 [==============================] - 3s 74us/sample - loss: 2.9957 - accuracy: 0.0486 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 15/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0509 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 16/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 17/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 18/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0482 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 19/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 20/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 21/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 22/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 23/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 24/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0488 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 25/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0507 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 26/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 27/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0502 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 28/50\n",
            "44000/44000 [==============================] - 3s 78us/sample - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 29/50\n",
            "44000/44000 [==============================] - 3s 78us/sample - loss: 2.9957 - accuracy: 0.0480 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 30/50\n",
            "44000/44000 [==============================] - 3s 78us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 31/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0497 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 32/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0506 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 33/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 34/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 35/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0502 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 36/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 37/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 38/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 39/50\n",
            "44000/44000 [==============================] - 3s 78us/sample - loss: 2.9957 - accuracy: 0.0487 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 40/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 41/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0503 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 42/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0505 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 43/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 44/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 45/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 46/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0483 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 47/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 48/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 49/50\n",
            "44000/44000 [==============================] - 3s 78us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 50/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "44000/44000 [==============================] - 4s 101us/sample - loss: 2.9960 - accuracy: 0.0487 - val_loss: 2.9961 - val_accuracy: 0.0448\n",
            "Epoch 2/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 3.0030 - accuracy: 0.0499 - val_loss: 2.9961 - val_accuracy: 0.0510\n",
            "Epoch 3/50\n",
            "44000/44000 [==============================] - 3s 78us/sample - loss: 2.9958 - accuracy: 0.0498 - val_loss: 2.9963 - val_accuracy: 0.0475\n",
            "Epoch 4/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9958 - accuracy: 0.0500 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 5/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9958 - accuracy: 0.0492 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 6/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9958 - accuracy: 0.0494 - val_loss: 2.9964 - val_accuracy: 0.0457\n",
            "Epoch 7/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9958 - accuracy: 0.0497 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 8/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9958 - accuracy: 0.0498 - val_loss: 2.9963 - val_accuracy: 0.0448\n",
            "Epoch 9/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0492 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 10/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9958 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 11/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9958 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 12/50\n",
            "44000/44000 [==============================] - 3s 78us/sample - loss: 2.9958 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 13/50\n",
            "44000/44000 [==============================] - 3s 78us/sample - loss: 2.9958 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 14/50\n",
            "44000/44000 [==============================] - 3s 79us/sample - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 15/50\n",
            "44000/44000 [==============================] - 3s 78us/sample - loss: 2.9958 - accuracy: 0.0498 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 16/50\n",
            "44000/44000 [==============================] - 3s 78us/sample - loss: 2.9957 - accuracy: 0.0490 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 17/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0494 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 18/50\n",
            "44000/44000 [==============================] - 3s 78us/sample - loss: 2.9958 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 19/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 20/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0485 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 21/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 22/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 23/50\n",
            "44000/44000 [==============================] - 3s 78us/sample - loss: 2.9957 - accuracy: 0.0485 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 24/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 25/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0497 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 26/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 27/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 28/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0492 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 29/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 30/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 31/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 32/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 33/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 34/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0496 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 35/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 36/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 37/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0501 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 38/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0497 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 39/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 40/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 41/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 42/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 43/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 44/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0482 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 45/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 46/50\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.9957 - accuracy: 0.0493 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 47/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0497 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 48/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 49/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0497 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 50/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9958 - accuracy: 0.0490 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "44000/44000 [==============================] - 5s 111us/sample - loss: 2.9960 - accuracy: 0.0498 - val_loss: 2.9961 - val_accuracy: 0.0440\n",
            "Epoch 2/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9958 - accuracy: 0.0493 - val_loss: 2.9962 - val_accuracy: 0.0462\n",
            "Epoch 3/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9958 - accuracy: 0.0495 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 4/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9958 - accuracy: 0.0508 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 5/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9958 - accuracy: 0.0495 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 6/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9958 - accuracy: 0.0494 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 7/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9958 - accuracy: 0.0503 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 8/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9958 - accuracy: 0.0499 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 9/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9958 - accuracy: 0.0507 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 10/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0511 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 11/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0492 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 12/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0481 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 13/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 14/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 15/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 16/50\n",
            "44000/44000 [==============================] - 3s 78us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 17/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 18/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 19/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 20/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 21/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0502 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 22/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0506 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 23/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 24/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 25/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 26/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 27/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0506 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 28/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 29/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0493 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 30/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 31/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 32/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 33/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0497 - val_loss: 2.9964 - val_accuracy: 0.0457\n",
            "Epoch 34/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0480 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 35/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0486 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 36/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 37/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 38/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 39/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0492 - val_loss: 2.9965 - val_accuracy: 0.0448\n",
            "Epoch 40/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 41/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 42/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0494 - val_loss: 2.9964 - val_accuracy: 0.0457\n",
            "Epoch 43/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0509 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 44/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 45/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0494 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 46/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0494 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 47/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 48/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 49/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0503 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 50/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "44000/44000 [==============================] - 4s 101us/sample - loss: 2.9959 - accuracy: 0.0483 - val_loss: 2.9962 - val_accuracy: 0.0475\n",
            "Epoch 2/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 3.0173 - accuracy: 0.0489 - val_loss: 2.9960 - val_accuracy: 0.0440\n",
            "Epoch 3/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9959 - accuracy: 0.0501 - val_loss: 2.9962 - val_accuracy: 0.0440\n",
            "Epoch 4/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9958 - accuracy: 0.0483 - val_loss: 2.9962 - val_accuracy: 0.0462\n",
            "Epoch 5/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9958 - accuracy: 0.0488 - val_loss: 2.9963 - val_accuracy: 0.0462\n",
            "Epoch 6/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9958 - accuracy: 0.0497 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 7/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 8/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 9/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0485 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 10/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0489 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 11/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 12/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 13/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0505 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 14/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9958 - accuracy: 0.0493 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 15/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 16/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 17/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9958 - accuracy: 0.0491 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 18/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 19/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 20/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 21/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 22/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 23/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0493 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 24/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 25/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 26/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0484 - val_loss: 2.9965 - val_accuracy: 0.0448\n",
            "Epoch 27/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0506 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 28/50\n",
            "44000/44000 [==============================] - 3s 78us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 29/50\n",
            "44000/44000 [==============================] - 3s 78us/sample - loss: 2.9957 - accuracy: 0.0502 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 30/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 31/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 32/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0490 - val_loss: 2.9964 - val_accuracy: 0.0457\n",
            "Epoch 33/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9958 - accuracy: 0.0505 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 34/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 35/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 36/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0503 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 37/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 38/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 39/50\n",
            "44000/44000 [==============================] - 3s 78us/sample - loss: 2.9957 - accuracy: 0.0492 - val_loss: 2.9963 - val_accuracy: 0.0440\n",
            "Epoch 40/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 41/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0497 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 42/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0497 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 43/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 44/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0506 - val_loss: 2.9964 - val_accuracy: 0.0448\n",
            "Epoch 45/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0494 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 46/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 47/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9958 - accuracy: 0.0504 - val_loss: 2.9965 - val_accuracy: 0.0448\n",
            "Epoch 48/50\n",
            "44000/44000 [==============================] - 3s 77us/sample - loss: 2.9957 - accuracy: 0.0496 - val_loss: 2.9965 - val_accuracy: 0.0440\n",
            "Epoch 49/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Epoch 50/50\n",
            "44000/44000 [==============================] - 3s 76us/sample - loss: 2.9957 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0440\n",
            "Best acc of 0.5231666564941406 for (1,)\n",
            "Best loss of 2.996365784327189 for (19,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA9i-NxRnvFR",
        "colab_type": "code",
        "outputId": "6fa79b4a-7f82-49ac-cb57-5ccd66bf9127",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        }
      },
      "source": [
        "history = model.fit(x_train, r_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_val, r_val),\n",
        "#          callbacks = [cp_callback, stopping_callback],\n",
        "          shuffle=True)\n",
        "\n",
        "# We analyse the result:\n",
        "\n",
        "[train_loss, train_accuracy] = model.evaluate(x_train_small, r_train_small, verbose=0)\n",
        "print(\"Training set Accuracy:{:7.2f}\".format(train_accuracy))\n",
        "print(\"Training set Loss:{:7.4f}\\n\".format(train_loss))\n",
        "\n",
        "[val_loss, val_accuracy] = model.evaluate(x_val, r_val, verbose=0)\n",
        "print(\"Validation set Accuracy:{:7.2f}\".format(val_accuracy))\n",
        "print(\"Validation set Loss:{:7.4f}\\n\".format(val_loss))\n",
        "\n",
        "#Now we visualise what happened during training\n",
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 44000 samples, validate on 6000 samples\n",
            "Epoch 1/10\n",
            "44000/44000 [==============================] - 4s 89us/sample - loss: 2.8835 - accuracy: 0.0996 - val_loss: 2.6683 - val_accuracy: 0.1707\n",
            "Epoch 2/10\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 2.5911 - accuracy: 0.1943 - val_loss: 2.4712 - val_accuracy: 0.2260\n",
            "Epoch 3/10\n",
            "44000/44000 [==============================] - 3s 75us/sample - loss: 2.3842 - accuracy: 0.2585 - val_loss: 2.2875 - val_accuracy: 0.2905\n",
            "Epoch 4/10\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 2.2342 - accuracy: 0.3041 - val_loss: 2.1765 - val_accuracy: 0.3287\n",
            "Epoch 5/10\n",
            "44000/44000 [==============================] - 3s 74us/sample - loss: 2.1169 - accuracy: 0.3437 - val_loss: 2.0842 - val_accuracy: 0.3500\n",
            "Epoch 6/10\n",
            "44000/44000 [==============================] - 3s 74us/sample - loss: 1.9877 - accuracy: 0.3803 - val_loss: 1.9666 - val_accuracy: 0.3838\n",
            "Epoch 7/10\n",
            "44000/44000 [==============================] - 3s 74us/sample - loss: 1.9097 - accuracy: 0.4027 - val_loss: 1.9141 - val_accuracy: 0.4005\n",
            "Epoch 8/10\n",
            "44000/44000 [==============================] - 3s 73us/sample - loss: 1.8012 - accuracy: 0.4352 - val_loss: 1.8550 - val_accuracy: 0.4178\n",
            "Epoch 9/10\n",
            "44000/44000 [==============================] - 3s 74us/sample - loss: 1.6933 - accuracy: 0.4659 - val_loss: 1.8058 - val_accuracy: 0.4293\n",
            "Epoch 10/10\n",
            "44000/44000 [==============================] - 3s 74us/sample - loss: 1.6113 - accuracy: 0.4940 - val_loss: 1.7563 - val_accuracy: 0.4515\n",
            "Training set Accuracy:   0.54\n",
            "Training set Loss: 1.4684\n",
            "\n",
            "Validation set Accuracy:   0.45\n",
            "Validation set Loss: 1.7563\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAEKCAYAAAA7GmJIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyYL/B2tGHQSY8YgkAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7FvmgpjnvM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Bsii1lbnvRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfStMcmUnvLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCGwvdGJnvIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7f0TZrfnvC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbYSOMnjnu91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdRkFhLxnuur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}